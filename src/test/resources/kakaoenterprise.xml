<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>카카오엔터프라이즈 기술블로그 Tech&amp;(테크앤)</title>
<link>https://tech.kakaoenterprise.com/</link>
<description></description>
<language>ko</language>
<pubDate>Thu, 08 Oct 2020 21:17:48 +0900</pubDate>
<generator>TISTORY</generator>
<ttl>100</ttl>
<managingEditor>카카오엔터프라이즈</managingEditor>
<item>
<title>RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases</title>
<link>https://tech.kakaoenterprise.com/81</link>
<description>&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;시작하며&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;카카오엔터프라이즈 AI Lab(최동현, 신명철, 김응균)과 성균관대학교(신동렬)는 스파이더 챌린지(SPIDER Text-to-SQL Challenge) 성과를 바탕으로 한 공동 연구 논문인 &amp;lsquo;&lt;/span&gt;&lt;a href=&quot;https://arxiv.org/pdf/2004.03125.pdf&quot;&gt;&lt;span&gt;RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;rsquo;를 아카이브(arXiv)에 공개했습니다. 미국 예일대학교(Yale University)에서 주최한 스파이더 챌린지는 기업이 각종 데이터를 정리 보관할 때 사용하는 데이터베이스가 주어졌을 때 자연어 형태의 사용자 질의 문장을 SQL(Structured Query Language)&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문으로 변환해주는 NLI2DB(natural language interface to databases) 알고리즘의 정확도를 평가합니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;공동 연구팀이 새롭게 고안한 SPC(Statement Position Code) 기법은 NLI2DB 문제에서 슬롯(slot)&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;을 채울 때 중첩된 SELECT문을 더 정확하게 생성합니다. 실제로 대규모 영어 비라벨링 말뭉치를 사전학습한 언어 모델&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;인 BERT에 SPC 기법을 도입한 RYANSQL로 실험을 진행해본 결과, 스파이더 벤치마크 데이터셋에 대해 SOTA(현재 최고 성능의) 모델&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;보다 3.2%p 더 높은 58.2%의 정확도를 달성했습니다. 카카오엔터프라이즈는 현재의 슬롯 채우기 방식에서 더 나아가, 슬롯값을 후보정하는 방식 등으로 자사 NLI2DB 알고리즘의 성능을 높이는 연구를 진행할 계획입니다.&lt;/span&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Abstract&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Text-to-SQL is the problem of converting a user question into an SQL query, when the question and database are given. In this paper, we present a neural network approach called RYANSQL (Recursively Yielding Annotation Network for SQL) to solve complex Text-to-SQL tasks for cross-domain databases. Statement Position Code (SPC) is defined to transform a nested SQL query into a set of non-nested SELECT statements; a sketch-based slot filling approach is proposed to synthesize each SELECT statement for its corresponding SPC. Additionally, two input manipulation methods are presented to improve generation performance further. RYANSQL achieved 58.2% accuracy on the challenging Spider benchmark, which is a 3.2%p improvement over previous state-of-the-art approaches. At the time of writing, RYANSQL achieves the first position on the Spider leaderboard.&lt;/span&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Overall Architecture&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Figure &lt;/span&gt;&lt;span&gt;1 &lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;shows the overall network architecture. The input encoder consists of five layers: Embedding layer, Embedding Encoder layer, Question- Column Alignment layer, Table Encoder layer, and Question-Table Alignment layer. Table &lt;/span&gt;&lt;span&gt;2 &lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;shows the proposed sketch for a SELECT statement. The sketch-based slot-filling decoder predicts values for slots of the proposed sketch.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;794&quot; height=&quot;503&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/YlSP8/btqKgEZJPQY/4jCwdwRdPS0aliPQCerHi0/img.png' data-lightbox='lightbox' data-alt='[ Figure 1 ] Network architecture of the proposed input encoder. ⧺ represents vector concatenation, M represents max-pooling and S represents self-attention.'&gt;&lt;img src='https://blog.kakaocdn.net/dn/YlSP8/btqKgEZJPQY/4jCwdwRdPS0aliPQCerHi0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FYlSP8%2FbtqKgEZJPQY%2F4jCwdwRdPS0aliPQCerHi0%2Fimg.png' width=&quot;794&quot; height=&quot;503&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[ Figure 1 ] Network architecture of the proposed input encoder. ⧺ represents vector concatenation, M represents max-pooling and S represents self-attention.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure class='imageblock alignCenter' width=&quot;666&quot; height=&quot;241&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/tfx6L/btqKgFqO3a1/xlWfTqY0OxlsgCgEyhjy4K/img.png' data-lightbox='lightbox' data-alt='[ table 1 ] Proposed sketch for a SELECT statement. $TBL and $COL represent a table and a column, respectively. $AGG is one of {none, max, min, count, sum, avg}, $ARI is one of the arithmetic operators {none, -, +, *, / }, and $COND is one of the conditional operators {between, =, &amp;amp;gt;, &amp;amp;lt;, &amp;amp;gt;=, &amp;amp;lt;=, !=, in, like, is, exists}. $DIST and $NOT are boolean variables representing the existence of keywords DISTINCT and NOT, respectively. $ORD is a binary value for keywords ASC/DESC, and $CONJ is one of conjunctions {AND, OR}. $VAL is the value for WHERE/HAVING condition; $SEL represents the slot for another SELECT statement.'&gt;&lt;img src='https://blog.kakaocdn.net/dn/tfx6L/btqKgFqO3a1/xlWfTqY0OxlsgCgEyhjy4K/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Ftfx6L%2FbtqKgFqO3a1%2FxlWfTqY0OxlsgCgEyhjy4K%2Fimg.png' width=&quot;666&quot; height=&quot;241&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[ table 1 ] Proposed sketch for a SELECT statement. $TBL and $COL represent a table and a column, respectively. $AGG is one of {none, max, min, count, sum, avg}, $ARI is one of the arithmetic operators {none, -, +, *, / }, and $COND is one of the conditional operators {between, =, &amp;gt;, &amp;lt;, &amp;gt;=, &amp;lt;=, !=, in, like, is, exists}. $DIST and $NOT are boolean variables representing the existence of keywords DISTINCT and NOT, respectively. $ORD is a binary value for keywords ASC/DESC, and $CONJ is one of conjunctions {AND, OR}. $VAL is the value for WHERE/HAVING condition; $SEL represents the slot for another SELECT statement.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Experiments&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;The performance of the proposed system is compared with grammar-based systems GrammarSQL, Global-GNN and IRNet. Also, we compared the system performance with RCSQL, which so far showed the best performance on the Spider dataset using a sketch-based slot-filling approach. As can be observed from the table, the proposed system RYANSQL improves the previous slot filling based system RCSQL by a large margin of 15%p on the development dataset. With the use of BERT, our system outperforms the current state- of-the-art by 3.2%p on the hidden test dataset, in terms of exact matching accuracy.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;424&quot; height=&quot;282&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/I0lw5/btqKdGqguoG/y8eGf8GTm33rjKu8ERwnW0/img.png' data-lightbox='lightbox' data-alt='[Table 2 ] Comparison results with other state-of-the-art systems'&gt;&lt;img src='https://blog.kakaocdn.net/dn/I0lw5/btqKdGqguoG/y8eGf8GTm33rjKu8ERwnW0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FI0lw5%2FbtqKdGqguoG%2Fy8eGf8GTm33rjKu8ERwnW0%2Fimg.png' width=&quot;424&quot; height=&quot;282&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[Table 2 ] Comparison results with other state-of-the-art systems&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/csgtWd/btqJ93Ghc0x/5UKviUvctOIhx6ljgABoh0/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/csgtWd/btqJ93Ghc0x/5UKviUvctOIhx6ljgABoh0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcsgtWd%2FbtqJ93Ghc0x%2F5UKviUvctOIhx6ljgABoh0%2Fimg.png' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;최동현(heuristic)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;어느새 30대 중반으로 접어든, 그러나 마음만은 젊게 지내는 인공지능 개발자입니다. 2017년에 카카오로 이직하며 카카오미니 개발에 참여하게 되었습니다. 카카오미니에 기여를 할 수 있어서 매우 기쁘고 미니를 좀 더 똑똑하게 만들기 위하여 열심히 공부 중에 있습니다.&lt;/p&gt;
&lt;p class=&quot;desc&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/b0P983/btqKfrfixxn/dfgSh96C3gmvF7VWzi1Etk/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/b0P983/btqKfrfixxn/dfgSh96C3gmvF7VWzi1Etk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb0P983%2FbtqKfrfixxn%2FdfgSh96C3gmvF7VWzi1Etk%2Fimg.png' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;신명철(index)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;외부 지식을 자연어 이해 과정에 인코딩하는 데 관심이 많은 개발자입니다. 최근 폭발하는 연구 결과에 짓눌려서 정신이 혼미하네요. 최대한 따라가려고 노력하고 있습니다.&lt;/p&gt;
&lt;p class=&quot;desc&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/ddKgGV/btqJ8f738qf/mM47eshaKNSczagrB9oOO1/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/ddKgGV/btqJ8f738qf/mM47eshaKNSczagrB9oOO1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FddKgGV%2FbtqJ8f738qf%2FmM47eshaKNSczagrB9oOO1%2Fimg.png' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;김응균(jason)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;한국어와 한글을 사랑하는 자연어처리 개발자입니다.&lt;/p&gt;
&lt;p class=&quot;desc&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;desc&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-recruit&quot;&gt;&lt;img class=&quot;img-recruit&quot; src=&quot;https://mk.kakaocdn.net/dn/kep-web/kep-blog/img_recruit.png&quot; /&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;새로운 길에 도전하는 최고의 Krew들과 함께 해요!&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://kakaoenterprise.recruiter.co.kr/app/jobnotice/view?systemKindCode=MRS2&amp;amp;jobnoticeSn=16933&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[AI기술] 자연어 처리 전문가 모집&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<category>AI Research</category>
<category>AILAB</category>
<category>challenge</category>
<category>NLI2DB</category>
<category>NLP</category>
<category>RYANSQL</category>
<category>SQL</category>
<category>데이터베이스</category>
<category>스파이더 챌린지</category>
<category>자연어처리파트</category>
<category>카카오엔터프라이즈</category>
<author>samantha.her</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/81</guid>
<comments>https://tech.kakaoenterprise.com/81#entry81comment</comments>
<pubDate>Thu, 08 Oct 2020 14:12:51 +0900</pubDate>
</item>
<item>
<title>JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment</title>
<link>https://tech.kakaoenterprise.com/80</link>
<description>&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;시작하며&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;카카오(임단)와 카카오엔터프라이즈 AI Lab(장원, 오경환, 박혜영, 김봉완, 윤재삼)이 함께 쓴 논문 &amp;lsquo;&lt;/span&gt;&lt;a href=&quot;https://arxiv.org/pdf/2005.07799.pdf&quot;&gt;&lt;span&gt;JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;(이하 JDI-T)&amp;rsquo;가 &lt;/span&gt;&lt;a href=&quot;http://www.interspeech2020.org/&quot;&gt;&lt;span&gt;Interspeech&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;에 게재 승인됐습니다. Interspeech는 음성 처리 과학기술 분야의 논문을 발표하는 세계 최대 규모의 학술 대회입니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;FastSpeech와 DurIAN과 같은 최신의 음성 합성 모델은 오류가 없는 고품질의 멜-스펙트로그램(Mel-spectrogram)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_80_1&quot; href=&quot;#footnote_80_1&quot; onmouseover=&quot;tistoryFootnote.show(this,80,1)&quot; onmouseout=&quot;tistoryFootnote.hide(80,1)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;1&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt; 생성에 탁월합니다. 하지만 훈련에 필요한 음소(phoneme)의 길이 정보를 확보하기 위해서는 합성 모델과는 별도로, 음소와 오디오를 명시적으로 정렬(explicit alignment)하는 모델을 따로 준비해야 하는 번거로움이 따릅니다. 이에 AI Lab은 음성합성 모델과 음소-오디오 정렬 모델을 한꺼번에 훈련(joint training)하는 아키텍처인 JDI-T를 제안했습니다. AI Lab이 제안한 모델은 자사 내부 데이터와 공개 한국어 데이터셋인 KSS(Korean Single Speaker Speech)에서 다른 최신 음성 합성 모델과 비교해 우수한 성능을 보였습니다. AI Lab은 향후 다양한 시나리오를 대비해 자사 음성 합성 기술을 고도화한다는 계획입니다.&lt;/span&gt;&lt;/p&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Abstract&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;We propose Jointly trained Duration Informed Transformer (JDI-T), a feed-forward Transformer with a duration predictor jointly trained without explicit alignments in order to generate an acoustic feature sequence from an input text. In this work, inspired by the recent success of the duration informed networks such as FastSpeech and DurIAN, we further simplify its sequential, two-stage training pipeline to a single-stage training. Specifically, we extract the phoneme duration from the autoregressive Transformer on the fly during the joint training instead of pre-training the autoregressive model and using it as a phoneme duration extractor. To our best knowledge, it is the first implementation to jointly train the feed-forward Transformer without relying on a pre-trained phoneme duration extractor in a single training pipeline. We evaluate the effectiveness of the proposed model on the publicly available Korean Single speaker Speech (KSS) dataset compared to the baseline text-to-speech (TTS) models trained by ESPnet-TTS.&lt;/span&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Overall Architecture&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;The proposed model, consisting of the feed-forward Transformer, the duration predictor, and the autoregressive Transformer, is trained jointly without explicit alignments. After joint training, only the feed-forward Transformer with the duration predictor is used for fast and robust conversion from phoneme sequences to mel-spectrogram.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;599&quot; height=&quot;460&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/rPlhL/btqKbWtjRlh/PKYg8b3fnjTQyCjAjHLk8K/img.png' data-lightbox='lightbox' data-alt='[ Figure 1 ] An illustration of our proposed joint training framework (Auxiliary loss for attention is omitted for brevity.)'&gt;&lt;img src='https://blog.kakaocdn.net/dn/rPlhL/btqKbWtjRlh/PKYg8b3fnjTQyCjAjHLk8K/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrPlhL%2FbtqKbWtjRlh%2FPKYg8b3fnjTQyCjAjHLk8K%2Fimg.png' width=&quot;599&quot; height=&quot;460&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[ Figure 1 ] An illustration of our proposed joint training framework (Auxiliary loss for attention is omitted for brevity.)&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Experiments&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;To evaluate the effectiveness of the proposed model, we conduct the Mean Opinion Score(MOS) test . The proposed model, JDI-T, is compared with three different models, including Tacotron2, Transformer, and FastSpeech. Table 1 shows the results on two different datasets; the Internal and the KSS.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;332&quot; height=&quot;198&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bDDYae/btqKhlr55mm/xaio85nCpccGKWK2GJSdK1/img.png' data-lightbox='lightbox' data-alt='[ Table 1 ] Mean opinion scores (5-point scale)'&gt;&lt;img src='https://blog.kakaocdn.net/dn/bDDYae/btqKhlr55mm/xaio85nCpccGKWK2GJSdK1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbDDYae%2FbtqKhlr55mm%2Fxaio85nCpccGKWK2GJSdK1%2Fimg.png' width=&quot;332&quot; height=&quot;198&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[ Table 1 ] Mean opinion scores (5-point scale)&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;The score of our proposed model, which is also non-autoregressive and duration informed model like FastSpeech, is better than FastSpeech and even achieves the highest score among the TTS models in the Internal dataset. These results show that the joint training of the proposed model is beneficial for improving the audio quality as well as for simplifying the training pipeline.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;In addition to its high-quality speech synthesis, the proposed model has benefits of the robustness and fast speed at synthesis over the autoregressive, attention-based TTS models since it has the feed-forward structure and does not rely on an attention mechanism as in FastSpeech. Moreover, our internal test shows that Tacotron2 and Transformer have a high rate of synthesis error, especially when they are trained with the KSS dataset and synthesize the out-of-domain scripts. Note that the synthesized audio samples from the test scripts have no synthesis error.&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;116&quot; height=&quot;116&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/4oJp6/btqJ93lY7Dy/OZDC6r2SFktKEPCk0XGVTk/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/4oJp6/btqJ93lY7Dy/OZDC6r2SFktKEPCk0XGVTk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F4oJp6%2FbtqJ93lY7Dy%2FOZDC6r2SFktKEPCk0XGVTk%2Fimg.png' width=&quot;116&quot; height=&quot;116&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;임단(satoshi)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;기계학습에 흥미를 느껴서 대학원에서 음성인식을 연구하게 됐습니다. 운이 좋게도 현재는 카카오에서 가장 흥미로운 분야로 손꼽히는 음성합성의 연구와 개발을 담당하고 있습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;106&quot; height=&quot;106&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bSPTD7/btqKjcuFTiN/XNjau61YBgJsivzzqBogo1/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/bSPTD7/btqKjcuFTiN/XNjau61YBgJsivzzqBogo1/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbSPTD7%2FbtqKjcuFTiN%2FXNjau61YBgJsivzzqBogo1%2Fimg.jpg' width=&quot;106&quot; height=&quot;106&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;장원(taylor)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;보다 선명하고, 보다 인간적인 감정을 녹여낼 수 있는 미래 음성합성 기술을 연구하고 있습니다. 제 기술이 일상의 사소한 불편을 해소해나가려는 kakao i의 행보에 조금이라도 보탬이 됐으면 좋겠습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;120&quot; height=&quot;120&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bjgTBV/btqKfpV3WYI/8h1KLlRk0hnrB233KK4Dz1/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/bjgTBV/btqKfpV3WYI/8h1KLlRk0hnrB233KK4Dz1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjgTBV%2FbtqKfpV3WYI%2F8h1KLlRk0hnrB233KK4Dz1%2Fimg.png' width=&quot;120&quot; height=&quot;120&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;오경환(leo)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;카카오 엔터프라이즈의 훌륭한 동료와 함께 음성합성 기술을 연구하고 만듭니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;102&quot; height=&quot;102&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/2RGo3/btqJ92AzzDz/Pkfn01Unh0fzkeLWUidR50/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/2RGo3/btqJ92AzzDz/Pkfn01Unh0fzkeLWUidR50/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2RGo3%2FbtqJ92AzzDz%2FPkfn01Unh0fzkeLWUidR50%2Fimg.png' width=&quot;102&quot; height=&quot;102&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;박혜영(abigail)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;&amp;rsquo;딥러닝&amp;rsquo;이라는 마법같은 기술로 다양하고 개성있는 목소리를 만들고 싶은, 꿈쟁이 개발자입니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;113&quot; height=&quot;112&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/b7Uw3V/btqJ6dWUPuf/pElUW8gRC3Aku0VrzPxYTK/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/b7Uw3V/btqJ6dWUPuf/pElUW8gRC3Aku0VrzPxYTK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb7Uw3V%2FbtqJ6dWUPuf%2FpElUW8gRC3Aku0VrzPxYTK%2Fimg.png' width=&quot;113&quot; height=&quot;112&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;김봉완(montae)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;훌륭한 동료들과 함께, 보다 자연스럽고 편안한 음성 합성 기술을 만들고 있습니다. 이 기술이 모두의 삶의 질을 높이는 데 도움이 됐으면 좋겠습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;118&quot; height=&quot;118&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/k0q4X/btqKbV8201w/TmPEORNON4xAu4OKFQfCfK/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/k0q4X/btqKbV8201w/TmPEORNON4xAu4OKFQfCfK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fk0q4X%2FbtqKbV8201w%2FTmPEORNON4xAu4OKFQfCfK%2Fimg.png' width=&quot;118&quot; height=&quot;118&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;윤재삼(jeff)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;사람과 사물이 자연스럽게 연결되는 세상을 위한 음성합성 기술을 연구합니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-recruit&quot;&gt;&lt;img class=&quot;img-recruit&quot; src=&quot;https://mk.kakaocdn.net/dn/kep-web/kep-blog/img_recruit.png&quot; /&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;새로운 길에 도전하는 최고의 Krew들과 함께 해요!&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://kakaoenterprise.recruiter.co.kr/app/jobnotice/view?systemKindCode=MRS2&amp;amp;jobnoticeSn=16933&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[AI기술] 자연어 처리 전문가 모집&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;div class=&quot;footnotes&quot;&gt;
&lt;ol class=&quot;footnotes&quot;&gt;
&lt;li id=&quot;footnote_80_1&quot;&gt;음성 신호를 멜 스케일(mel-scale)에 따라 주파수를 분석하여 얻은 특징 벡터로, 기계학습 모델에서 음성을 나타내는 데 주로 쓰인다. &lt;a href=&quot;#footnote_link_80_1&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
<category>AI Research</category>
<category>AI Lab</category>
<category>Interspeech</category>
<category>JDI-T</category>
<category>Korean speech</category>
<category>speech synthesis</category>
<category>transformer</category>
<category>TTS</category>
<category>음성처리파트</category>
<category>카카오엔터프라이즈</category>
<author>samantha.her</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/80</guid>
<comments>https://tech.kakaoenterprise.com/80#entry80comment</comments>
<pubDate>Thu, 08 Oct 2020 14:12:02 +0900</pubDate>
</item>
<item>
<title>Deep Metric Learning with Multi-Objective Functions</title>
<link>https://tech.kakaoenterprise.com/74</link>
<description>&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;시작하며&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;카카오엔터프라이즈 AI Lab(이주영, 노명철)이 쓴 논문 &amp;lsquo;&lt;/span&gt;&lt;a href=&quot;https://drive.google.com/file/d/1co4JkFhxob75MyV8yws-8mgGqGw2PrC8/view?fbclid=IwAR3z4hL31A5HoyPJs4v3aVlw4TStOJtCEn1bnWY_EixQrUSMyJdJokqfR5c&quot;&gt;&lt;span&gt;Deep Metric Learning with Multi-Objective Functions&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;rsquo;이 컴퓨터 비전 및 패턴 인식 컨퍼런스(CVPR) 워크숍 주제 중 하나인 &lt;/span&gt;&lt;a href=&quot;https://sites.google.com/view/cvcreative2020&quot;&gt;&lt;span&gt;CVFAD&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;(Computer Vision for Fashion, Art and Design)에 게재 승인됐습니다. 올해로 3번째 열린 CVFAD에서는 패션, 예술, 디자인 등의 창의성이 요구되는 분야에 필요한 생성 모델(generative models), 검색(retrieval), 제품 추천(product recommendation), 이미지 분할(image segmentation), 속성 인식(attribute discovery), 트렌드 예측(trend forecast) 등에 관한 최신의 컴퓨터 비전과 머신러닝 방법론을 다룹니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;AI Lab은 패션 이미지를 효율적으로 검색하는 거리 학습(metric learning) 방법론을 제안했습니다. 기존의 페어(pair)/트리플렛(triplet) 기반 손실 함수와 프록시(proxy) 기반 손실 함수를 동시에 훈련하면서도, 이 과정에서 발생하는 샘플링(sampling)과 초매개변수(hyperparameter) 관련 문제를 해결했습니다. 제안된 방법은 In-Shop Clothes Retrieval 데이터셋에 대해 현재 최고 수준의(SOTA) 성능을 얻을 수 있었습니다. AI Lab은 이번 연구로 얻은 기술력과 경험을 바탕으로 카카오 i의 시각 엔진과 딥러닝 기반 유사 스타일 추천 기술을 고도화한다는 계획입니다.&lt;/span&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Abstract&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Metric learning is a very important process for the efficient fashion image retrieval and, in the metric learning, one of the most important issues is the selection of which objective functions. Efficient object functions in the previous work are pair/triplet based loss and proxy based one. Two types of objective functions have disadvantages that are opposed to each advantage. The loss functions have their own strengths, but their strengths oppose each other. To overcome the disadvantages, we propose a method that can simultaneously train the multi-objective functions. We achieve the new state-of-the art performance on In-Shop Clothes Retrieval dataset.&lt;/span&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Overall Architecture&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;The proposed method explicitly considered the three types of distances (or similarities), each of which corresponds to three types of objective functions are defined as: 1) pairwise loss function optimized using embeddings of given samples, 2) proxy-based loss function used the similarity between proxies and embeddings of given samples, and 3) loss function minimized the similarity between proxies, respectively. Since each loss function has a different amount of contribution to optimize the method, we analyze the contribution and propose a combination method considering this. Finally, because the existing sampling strategies are mainly based on a single anchor, the sampling strategies are impossible to consider each relation of an anchor and a proxy together. We also propose a sampling strategy to consider two types of relations, at the same time.&lt;/span&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;623&quot; height=&quot;365&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/268Lb/btqGX4AaXVp/qVOOvBBDYFueNdA4k5FcvK/img.png' data-lightbox='lightbox' data-alt='[Figure 1] Comparison with the previous and our method'&gt;&lt;img src='https://blog.kakaocdn.net/dn/268Lb/btqGX4AaXVp/qVOOvBBDYFueNdA4k5FcvK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F268Lb%2FbtqGX4AaXVp%2FqVOOvBBDYFueNdA4k5FcvK%2Fimg.png' width=&quot;623&quot; height=&quot;365&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[Figure 1] Comparison with the previous and our method&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Experiments&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;We now compare the proposed method to other state-of-the art methods on In-shop Clothes Retrieval dataset. As shown in Table 1, the proposed method improves Recall@1 by 0.4%p, it is achieved to the new state-of-the art performance.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;614&quot; height=&quot;201&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bkwVsg/btqGYKBsS5v/mtE4PxkyKQqKQUpvLDaOSK/img.png' data-lightbox='lightbox' data-alt='[Table 1] Retrieval performance (Recall@K, %). Superscripts denote embedding size.'&gt;&lt;img src='https://blog.kakaocdn.net/dn/bkwVsg/btqGYKBsS5v/mtE4PxkyKQqKQUpvLDaOSK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkwVsg%2FbtqGYKBsS5v%2FmtE4PxkyKQqKQUpvLDaOSK%2Fimg.png' width=&quot;614&quot; height=&quot;201&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[Table 1] Retrieval performance (Recall@K, %). Superscripts denote embedding size.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;184&quot; height=&quot;184&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/cyIYfo/btqGX5sjHsC/7kqOWLkBT4JiNCox6C7hQk/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/cyIYfo/btqGX5sjHsC/7kqOWLkBT4JiNCox6C7hQk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcyIYfo%2FbtqGX5sjHsC%2F7kqOWLkBT4JiNCox6C7hQk%2Fimg.png' width=&quot;184&quot; height=&quot;184&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;이주영(michael)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;카카오엔터프라이즈에서 쇼핑∙검색 이미지 분석 관련 연구∙개발 조직을 맡고 있습니다. 많은 사람이 즐겁게 이용할 수 있는 인공지능 기술을 만들고 싶습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;186&quot; height=&quot;186&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/ekSV7Z/btqGX4GVEuF/9DjXtgGhwLY1PzKuZOdceK/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/ekSV7Z/btqGX4GVEuF/9DjXtgGhwLY1PzKuZOdceK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FekSV7Z%2FbtqGX4GVEuF%2F9DjXtgGhwLY1PzKuZOdceK%2Fimg.png' width=&quot;186&quot; height=&quot;186&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;노명철(joshua))&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;카카오엔터프라이즈에서 훌륭한 동료들과 함께 얼굴 인식 관련 기술을 연구∙개발하고 있습니다. 기계의 성능 수치보다는, 사람의 행복 지수를 높이는 인공지능 기술을 만들고 싶습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-recruit&quot;&gt;&lt;img class=&quot;img-recruit&quot; src=&quot;https://mk.kakaocdn.net/dn/kep-web/kep-blog/img_recruit.png&quot; /&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;새로운 길에 도전하는 최고의 Krew들과 함께 해요!&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://kakaoenterprise.recruiter.co.kr/app/jobnotice/view?systemKindCode=MRS2&amp;amp;jobnoticeSn=17233&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[AI기술] 컴퓨터비전 및 머신러닝 전문가 모집&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<category>AI Research</category>
<category>AI Lab</category>
<category>CVFAD</category>
<category>cvpr</category>
<category>Loss Function</category>
<category>metric learning</category>
<category>PAPER</category>
<category>retrieval</category>
<category>카카오엔터프라이즈</category>
<category>카카오엔터프라이즈 채용</category>
<author>samantha.her</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/74</guid>
<comments>https://tech.kakaoenterprise.com/74#entry74comment</comments>
<pubDate>Fri, 18 Sep 2020 13:47:21 +0900</pubDate>
</item>
<item>
<title>기계 독해를 이용한 웹 기반 오픈 도메인 한국어 질의응답</title>
<link>https://tech.kakaoenterprise.com/71</link>
<description>&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;시작하며&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;카카오엔터프라이즈 AI Lab(최동현, 김응균)이 성균관대학교(신동렬)와 함께 쓴 논문 &amp;lsquo;기계 독해를 이용한 웹 기반 오픈 도메인 한국어 질의응답&amp;rsquo;이 &lt;/span&gt;&lt;a href=&quot;http://hclt.kr/symp/?lnb=conference&quot;&gt;&lt;span&gt;제31회 한글 및 한국어정보처리 학술대회&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;에 실렸습니다. 한글날을 맞이해 매년 10월마다 열리는 한글 및 한국어정보처리 학술대회는 전산언어학과 언어학, 인공지능과 관련된 다양한 주제의 연구 논문을 다루고 있습니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;AI Lab은 기계 독해를 이용한 웹 기반 오픈 도메인 한국어 질의응답 시스템을 제안했습니다. 시스템에 사용자 질의가 입력되면, 기존의 검색 엔진으로 최대 1,500개의 문서를 기계 독해 방식으로 실시간으로 분석합니다. 그런 뒤, 각 문서에서 찾은 답을 종합해 최종 답변을 도출합니다. 실험 결과, 제안된 시스템의 평균 실행 시간은 2초 이내였으며, 인간이 기록한 점수 대비 86%에 달하는 준수한 성능을 냈습니다. AI Lab이 제안한 시스템의 데모는 카카오의 &lt;/span&gt;&lt;a href=&quot;http://nlp-api.kakao.com/&quot;&gt;&lt;span&gt;NLP API 페이지&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;에서 확인할 수 있습니다.&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;전체 구조&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;기계학습 기반 한국어 오픈 도메인 질의응답 시스템은 5개의 부분 시스템&amp;ndash;질의 분석기, 검색 질의 생성기, 검색 결과 정제기, 기계 독해기, 최종 정답 추출기&amp;ndash;로 나뉘어 질 수 있다. 제안된 시스템은 일반적인 키워드 기반 검색 엔진에 의해 색인된 수십억 개의 한국어 웹 페이지를 이용한다. 신뢰도 이슈를 해결하기 위하여, 기계 독해 시스템을 이용하여 실시간으로 최대 1,500개의 웹 페이지로부터 후보 정답을 추출하며, 최종 정답은 얻어진 후보 정답들을 재차 분석하여 얻어&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;진다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;794&quot; height=&quot;367&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/OOqIa/btqGspk1TIV/KQQYyOlQpFlHDKjpKs0sjK/img.png' data-lightbox='lightbox' data-alt='[그림 1] 제안된 전체 시스템 구조'&gt;&lt;img src='https://blog.kakaocdn.net/dn/OOqIa/btqGspk1TIV/KQQYyOlQpFlHDKjpKs0sjK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FOOqIa%2FbtqGspk1TIV%2FKQQYyOlQpFlHDKjpKs0sjK%2Fimg.png' width=&quot;794&quot; height=&quot;367&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 1] 제안된 전체 시스템 구조&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;실험&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;전체 시스템의 성능을 평가하기 위하여, 육하원칙 카테고리 WHAT, WHEN, WHERE, WHO에 대하여 각 200개씩의 질문이 수집되었다. 각 질문에 대하여 두 명의 어노테이터가 답변을 구축한 후, 결과물이 수집되었다. 문제의 특성상, 하나의 질문이 여러 개의 답변을 가지는 것이 허용되었다. 표 1는 말뭉치에 포함된 질문-답변 예시를 보여 준다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;388&quot; height=&quot;179&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/txGpb/btqGpAnQO0L/7HnQFlJelDrjI3h8vKjd4K/img.png' data-lightbox='lightbox' data-alt='[표 1] 질문-답변 말뭉치 데이터 예시'&gt;&lt;img src='https://blog.kakaocdn.net/dn/txGpb/btqGpAnQO0L/7HnQFlJelDrjI3h8vKjd4K/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtxGpb%2FbtqGpAnQO0L%2F7HnQFlJelDrjI3h8vKjd4K%2Fimg.png' width=&quot;388&quot; height=&quot;179&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[표 1] 질문-답변 말뭉치 데이터 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;표 2에서 관찰 가능하듯이, 제안된 시스템은 F1 70.6%의 성능을 보여 주었고, 이는 사람이 기록한 F1 점수 대비 86%에 도달하는 것이다. WHAT 카테고리의 경우, 서술형 답변을 많이 포함하고 있어 다른 육하원칙 카테고리에 속하는 질의에 비해 낮은 성능을 보여 주었다. 또한, 시스템의 질의당 평균 실행 시간은 1.6초, 최대 실행 시간은 4.7초를 기록하여, 실시간으로 사용될 수 있는 실행 시간이 확인되었다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;485&quot; height=&quot;134&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/cU0dJV/btqGpAakNe1/KVCbkYKxxQWkHCbGPTwWW1/img.png' data-lightbox='lightbox' data-alt='[표 2] 시스템 성능 평가'&gt;&lt;img src='https://blog.kakaocdn.net/dn/cU0dJV/btqGpAakNe1/KVCbkYKxxQWkHCbGPTwWW1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcU0dJV%2FbtqGpAakNe1%2FKVCbkYKxxQWkHCbGPTwWW1%2Fimg.png' width=&quot;485&quot; height=&quot;134&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[표 2] 시스템 성능 평가&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/2L2KY/btqGsnHsWmA/QsRnnGJFjTtAoPNGQGcTM0/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/2L2KY/btqGsnHsWmA/QsRnnGJFjTtAoPNGQGcTM0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2L2KY%2FbtqGsnHsWmA%2FQsRnnGJFjTtAoPNGQGcTM0%2Fimg.png' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;최동현(heuristic)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;어느새 30대 중반으로 접어든, 그러나 마음만은 젊게 지내는 인공지능 개발자입니다. 2017년에 카카오로 이직하며 카카오미니 개발에 참여하게 되었습니다. 카카오미니에 기여를 할 수 있어서 매우 기쁘고 미니를 좀 더 똑똑하게 만들기 위하여 열심히 공부 중에 있습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/csbrVQ/btqGrjFjFp6/dFyvRs5z8RYSBT8h9uDa11/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/csbrVQ/btqGrjFjFp6/dFyvRs5z8RYSBT8h9uDa11/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcsbrVQ%2FbtqGrjFjFp6%2FdFyvRs5z8RYSBT8h9uDa11%2Fimg.png' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;김응균(jason)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;한국어와 한글을 사랑하는 자연어처리 개발자입니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-recruit&quot;&gt;&lt;img class=&quot;img-recruit&quot; src=&quot;https://mk.kakaocdn.net/dn/kep-web/kep-blog/img_recruit.png&quot; /&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;새로운 길에 도전하는 최고의 Krew들과 함께 해요!&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://kakaoenterprise.recruiter.co.kr/app/jobnotice/view?systemKindCode=MRS2&amp;amp;jobnoticeSn=16933&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[AI기술] 자연어 처리 전문가 모집&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<category>AI Research</category>
<category>AI Lab</category>
<category>NLP</category>
<category>기계독해</category>
<category>자연어처리파트</category>
<category>질의응답</category>
<category>카카오엔터프라이즈</category>
<category>카카오엔터프라이즈 면접</category>
<author>samantha.her</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/71</guid>
<comments>https://tech.kakaoenterprise.com/71#entry71comment</comments>
<pubDate>Thu, 03 Sep 2020 21:18:19 +0900</pubDate>
</item>
<item>
<title>카카오 i의 작고 소중한 힐링</title>
<link>https://tech.kakaoenterprise.com/67</link>
<description>&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span&gt;시작하며&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;서기 2020년! 우리는 접촉이 공포가 되는 극단적 언택트(Untact) 시대를 맞이하고 말았습니다. 사람보다는 키오스크, 전화보다는 배달 앱, 발품보다는 온라인 쇼핑이 편해진 건 그다지 새로운 이야기도 아니지만, &amp;lsquo;안&amp;rsquo;하는 것과 &amp;lsquo;못&amp;rsquo;하는 것은 아주 다르니까요. 실생활의 불편함은 물론이고 불안, 무기력, 우울감을 호소하는 코로나 블루까지 우리의 일상은 꽤 많이 바뀌었습니다. 저 역시도 재택근무로 외로움이 짙어질 즈음에 모든 콘택트 요청이 단비 같았죠. 설령 그게 업무 요청일지라도... (언빌리버블!)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;오늘은 언택트 시대의 힐링 서비스를 통해 사람들의 위로가 되고 싶은 마음을 전하고자 합니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;기술 공유보단 옆집 사는 기획자 이야기로 편히 읽어주세요.  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;스크린샷 2020-08-07 오전 11.43.33.png&quot; data-origin-width=&quot;1522&quot; data-origin-height=&quot;612&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/b3rDOs/btqGnHr31fQ/srgXzZk4CsdKWD1Fhv4A30/img.png' data-lightbox='lightbox' data-alt='&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;[그림 1] 2020년 1월~ 5월 발화량 상승 비율&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;[그림 2] 2020년 1월~ 6월 &amp;amp;lsquo;힐링사운드'와 &amp;amp;lsquo;코로나' 관련 키워드&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;&amp;amp;nbsp;'&gt;&lt;img src='https://blog.kakaocdn.net/dn/b3rDOs/btqGnHr31fQ/srgXzZk4CsdKWD1Fhv4A30/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb3rDOs%2FbtqGnHr31fQ%2FsrgXzZk4CsdKWD1Fhv4A30%2Fimg.png' data-filename=&quot;스크린샷 2020-08-07 오전 11.43.33.png&quot; data-origin-width=&quot;1522&quot; data-origin-height=&quot;612&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;[그림 1] 2020년 1월~ 5월 발화량 상승 비율&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;[그림 2] 2020년 1월~ 6월 &amp;lsquo;힐링사운드'와 &amp;lsquo;코로나' 관련 키워드&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;상반기에 인입된 발화를 살펴보면 [그림 1]과 같이 1월 대비 4월 발화가 30% 정도 증가했는데요. 특히 &amp;lsquo;힐링&amp;rsquo;이 포함된 발화는 2배 이상, &amp;lsquo;힐링사운드' 분류 발화 역시 2배 가까이 늘어난 것을 볼 수 있습니다. 혼자 있어서, 집에서 일이나 공부를 해야 해서, 휴식이 필요해서&amp;hellip; 원인은 다양하지만, 확실한 건 우리가 할 일이 더 많아질 거라는 점이죠. 미니는 정보를 주는 &amp;lsquo;비서' 이상의 위로가 될 수 있는 &amp;lsquo;친구'니까요. (&lt;/span&gt;&lt;a href=&quot;https://tech.kakaoenterprise.com/60?category=882488&quot;&gt;&lt;span&gt;카카오 i의 페르소나&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;)&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span&gt;조용하고 싶지만 적막한 건 싫은, 백색소음 힐링&lt;/span&gt;&lt;/h2&gt;
&lt;h4 data-ke-size=&quot;size20&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;#소음이 가져다준 뜻밖의 힐링&lt;/span&gt;&lt;/h4&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;그럴 때 있잖아요. 혼자 있고 싶지만 혼자 있기 싫고, 조용하고 싶지만 너무 조용한 건 싫을 때.  &lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;불규칙한 잡음은 긴장을 주지만, 성분과 세기가 골고루 분포된 소리는 잡음을 상쇄시키고 심신안정에 도움을 줍니다. 실제로 폭포 소리나 새소리를 듣고 헤모글로빈의 농도가 저하된 실험, 소음이 청각 지각에 도움을 준다는 연구 결과도 있죠. 이러한 '백색소음'은 집중과 안정, 그리고 꿀잠을 돕는 슬립 테크의 일환으로 꾸준히 주목받아 왔습니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;사람들은 백색소음을 어디에서 찾을까. 음악 서비스, 유튜브에서도 자연의 소리, 도서관 소리, (아이를 재운다는 ) 청소기 소리 등이 높은 조회 수를 기록합니다. 또한, 고가의 백색소음 전용 기기도 인기를 얻고 있는데요. 그에 비해 AI 스피커는 말 한마디면 틀 수 있고 다재다능하다는 장점을 가지고 있죠. 최근 알렉사 등 AI 스피커들은 집에서의 작업과 휴식을 위해 카페, 사무실, 해변 등 일상의 사운드를 확대 강화하고 있습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;h4 data-ke-size=&quot;size20&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;#카카오 i 힐링사운드 시작&lt;/span&gt;&lt;/h4&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;그래서 우리는 사회공헌 플랫폼 &lt;a style=&quot;color: #000000;&quot; href=&quot;https://together.kakao.com/mind/sounds&quot;&gt;카카오같이가치&lt;/a&gt;에서 제공하는 백색소음류 힐링사운드를 연동하기로 했습니다. 요약하면 발화의 의도를 파악하여 힐링사운드로 '분류'하고, &amp;lsquo;엔티티'라고 불리는 키워드를 추출하여, 음원을 찾는 '스킬'을 연결하는 과정입니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;상세한 과정은 &lt;a style=&quot;color: #000000;&quot; href=&quot;https://tech.kakaoenterprise.com/43?category=882488&quot;&gt;카카오미니의 명령어 분류 방법&lt;/a&gt;에 기술되어 있는데요. 저는 서비스를 운영하는 기획자 입장에서 가볍게 말씀드리려 합니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;스크린샷 2020-08-07 오전 10.27.17.png&quot; data-origin-width=&quot;1462&quot; data-origin-height=&quot;820&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/blsWZc/btqGmU6vAay/ofpvvxmryN76kPbtEBsY61/img.png' data-lightbox='lightbox' data-alt='&amp;amp;nbsp;&amp;amp;nbsp;[그림 3] &amp;quot;빗소리 들려줘&amp;quot; 음성 인식 흐름&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp;[그림 4] &amp;quot;빗소리 들려줘&amp;quot; 재생 예시'&gt;&lt;img src='https://blog.kakaocdn.net/dn/blsWZc/btqGmU6vAay/ofpvvxmryN76kPbtEBsY61/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FblsWZc%2FbtqGmU6vAay%2FofpvvxmryN76kPbtEBsY61%2Fimg.png' data-filename=&quot;스크린샷 2020-08-07 오전 10.27.17.png&quot; data-origin-width=&quot;1462&quot; data-origin-height=&quot;820&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;&amp;nbsp;&amp;nbsp;[그림 3] &quot;빗소리 들려줘&quot; 음성 인식 흐름&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;[그림 4] &quot;빗소리 들려줘&quot; 재생 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;ldquo;힐링사운드 30분만 틀어줘&amp;rdquo;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;ldquo;빗소리 들려줘&quot;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;ldquo;새하얀 눈 밟는 소리 들려줘&quot;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;blockquote data-ke-size=&quot;size20&quot; data-ke-style=&quot;style3&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #666666;&quot;&gt;(1) 음성인식&amp;nbsp;&lt;/span&gt;&lt;/b&gt;&lt;/blockquote&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 비정형화된 신규 텍스트는 음성 학습 데이터가 쌓이기 전까지 불안정한 인식률을 보이기도 합니다. 그래서 서비스 오픈 전에 특수한 제목, 신규 명령어 등을 미리 학습시켜두면 높은 음성 인식률을 담보할 수 있죠.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 이런 관점에서 매일 크리에이티브한 곡명/아티스트 명이 생겨나는 &amp;lsquo;음악&amp;rsquo; 서비스는 음성 인식이 가장 까다로운 서비스 중에 하나랍니다.  &lt;/span&gt;&lt;/p&gt;
&lt;blockquote data-ke-size=&quot;size18&quot; data-ke-style=&quot;style3&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #666666;&quot;&gt;(2) 봇 분류&lt;/span&gt;&lt;/b&gt;&lt;b&gt;&lt;span style=&quot;color: #666666;&quot;&gt;&lt;/span&gt;&lt;/b&gt;&lt;/blockquote&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 음악/라디오/뉴스/주식/인물/실시간 검색어 등 약 70여 개의 봇 중에서 사용자의 의도를 파악하고 힐링사운드 봇을 선택하는 과정입니다. &lt;b&gt;&lt;/b&gt;분류의 기준은 &amp;lsquo;힐링사운드'라는 단서일 수도 있고, &amp;lsquo;틀어줘'라는 명령어일 수도 있고, &amp;lsquo;빗소리'라는 구체적인 콘텐츠명이 될 수도 있습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- &amp;lsquo;틀어줘'라는 명령어만으로는 원하는 것이 &amp;lsquo;음악'인지 &amp;lsquo;라디오'인지 &amp;lsquo;힐링사운드'인지 구분하기 어렵습니다. 그래서 &amp;lsquo;명령어' + '콘텐츠명' 등 핵심 단서를 기반으로 말뭉치(발화 예시)를 만들고 이를 기반으로 머신러닝을 하게 됩니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote data-ke-size=&quot;size20&quot; data-ke-style=&quot;style3&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #666666;&quot;&gt;(3) 인텐트 분류&lt;/span&gt;&lt;/b&gt;&lt;/blockquote&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 힐링사운드라는 봇 안에서 디테일한 의도를 파악하는 과정입니다. 봇 분류가 상위 카테고리라면, 인텐트 분류는 하위 카테고리라고 볼 수 있겠죠. 마찬가지로 분류를 위한 머신러닝이 필요합니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 힐링사운드 봇에는 아래와 같은 인텐트가 존재합니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;&amp;nbsp;ㄴ 사운드를 재생하는 &amp;ldquo;시냇물 소리 들려줘&quot;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;&amp;nbsp;ㄴ 제목을 알려주는 &amp;ldquo;이거 제목이 뭐야?&amp;rdquo;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;&amp;nbsp;ㄴ 어떤 콘텐츠가 있는지 알려주는 &amp;ldquo;힐링사운드 뭐 있어?&amp;rdquo;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;&amp;nbsp;ㄴ 재생을 컨트롤하는 &amp;ldquo;다음&amp;rdquo;, &amp;ldquo;이전&quot;, &amp;ldquo;그만&quot;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote data-ke-size=&quot;size20&quot; data-ke-style=&quot;style3&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #666666;&quot;&gt;(4) 슬롯 추출&lt;/span&gt;&lt;/b&gt;&lt;/blockquote&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 의도를 알았으니 실제 수행을 위한 핵심 정보를 추출해야 합니다. 미니에서는 슬롯 추출의 방법으로 엔티티 태깅(품사 태깅 중 하나)을 이용합니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 여기서 엔티티는 사운드 속성이나 상황별 추천 태그, 또는 사운드 제목으로 구성하였습니다. 아래 태깅 예시를 보면 이해가 쉬우실 것 같습니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;ㄴ 빗소리 들려줘: tag name=빗소리&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;ㄴ 공부할 때 힐링사운드 들려줘: tag name=공부할 때&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;ㄴ 새하얀 눈 밟는 소리 들려줘: sound name=새하얀 눈 밟는 소리&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 봇과 인텐트는 잘 찾았는데 원하는 음원을 재생하지 못하는 경우는 엔티티 태깅 정보가 잘못되었을 가능성이 큽니다. 이런 슬픈 결말을 막기 위해 엔티티 정의와 동의어 보강에도 힘써두어야 합니다. AI는 점술가가 아니기 때문에 데이터 룰을 촘촘히 해두는 것이 국룰이죠.  &lt;/span&gt;&lt;/p&gt;
&lt;blockquote data-ke-size=&quot;size20&quot; data-ke-style=&quot;style3&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #666666;&quot;&gt;(5) 요청 동작 수행&amp;nbsp;&lt;/span&gt;&lt;/b&gt;&lt;/blockquote&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;- 마지막으로 AI가 추출한 정보를 기반으로 &amp;lsquo;같이가치의 힐링사운드'에서 정보를 찾아서 미니로 재생하는 과정입니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span&gt;- &lt;span style=&quot;color: #000000;&quot;&gt;이 단계에서는 각 봇(도메인)의 목적과 구조에 맞는 정책을 적용할 수 있습니다. 힐링사운드에서는 &amp;lsquo;sound name&amp;rsquo;을 요청하면 해당 사운드를 반복하고, &quot;시냇물 소리 30분만 틀어줘&quot;와 같이 재생 시간을 지정할 수도 있죠. 이는 연속 재생의 니즈가 큰 콘텐츠 특성을 고려한 기능입니다.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span&gt;마음이 시끄러울 땐, 마음챙김 명상&lt;/span&gt;&lt;/h2&gt;
&lt;h4 data-ke-size=&quot;size20&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;#명상으로 마음 챙기기&lt;/span&gt;&lt;/h4&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;과거에는 마음을 돌보는 일에 소홀하기도 했지만, 최근 사회 전반에 불안이 번지면서 마음챙김의 중요성이 더 높아지고 있습니다. 잡념과 스트레스로 복잡해진 마음의 평안을 위해 같이가치 마음챙김 명상을 제공하게 되었습니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;스크린샷 2020-08-07 오전 11.31.19.png&quot; data-origin-width=&quot;1264&quot; data-origin-height=&quot;842&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/nD6s7/btqGiSH92On/TMTQgBE45uVs6r9CrsT3j0/img.png' data-lightbox='lightbox' data-alt='&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; [그림 5] &amp;quot;면역력을 높이는 명상 들려줘&amp;quot; 음성 인식 흐름&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; [그림 6]&amp;amp;nbsp; &amp;quot;면역력을 높이는 명상 들려줘&amp;quot;&amp;amp;nbsp; 재생 예시'&gt;&lt;img src='https://blog.kakaocdn.net/dn/nD6s7/btqGiSH92On/TMTQgBE45uVs6r9CrsT3j0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnD6s7%2FbtqGiSH92On%2FTMTQgBE45uVs6r9CrsT3j0%2Fimg.png' data-filename=&quot;스크린샷 2020-08-07 오전 11.31.19.png&quot; data-origin-width=&quot;1264&quot; data-origin-height=&quot;842&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; [그림 5] &quot;면역력을 높이는 명상 들려줘&quot; 음성 인식 흐름&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; [그림 6]&amp;nbsp; &quot;면역력을 높이는 명상 들려줘&quot;&amp;nbsp; 재생 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;ldquo;명상 들려줘&amp;rdquo;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;ldquo;아이와 함께하는 명상 시작&quot;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;ldquo;면역력 높이는 명상 틀어줘&quot;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;명상 서비스는 &amp;lsquo;힐링사운드 봇' 내에 명상 인텐트를 추가하는 방식으로 개발을 했습니다. 이러한 인텐트 세분화는 스킬 개발의 복잡도를 줄이는 대신 분류의 난이도를 높입니다. 목적지가 하나일 때는 그 안에서 분기 처리가 복잡해지고, 목적지가 쪼개져 있으면 가는 길의 기준을 세우기 어려워지기 때문이죠.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;분류에서 가장 까다로운 부분 중 하나가 중의적이거나 목적이 불분명한 발화입니다. 중요한 건 &amp;lsquo;사람이 구분할 수 있어야&amp;rsquo;만 &amp;lsquo;AI도 구분할 수 있다&amp;rsquo;는 점입니다. 친구가 다른 단서 없이 &amp;ldquo;위로가 되는 거 들려줘&quot;라고 한다면 바라는 것이 노래인지 이야기인지 단번에 알아채기 어렵겠죠. 그렇다고 어설프게 넘겨짚는 일이 반복되면 신뢰를 잃을지도 모르니까요. 이런 관점에서 사용 패턴과 컨텍스트를 분석하여 대충 말해도 찰떡같이 알아듣는 것이 카카오i의 과제이기도 합니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span&gt;시가 주는 담담한 위로, 셀럽 힐링사운드&lt;/span&gt;&lt;/h2&gt;
&lt;h4 data-ke-size=&quot;size20&quot;&gt;&lt;span style=&quot;color: #9d9d9d;&quot;&gt;#익숙한 목소리로 듣는 시의 감동&lt;/span&gt;&lt;/h4&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;최근 카카오같이가치와 BH엔터테인먼트 그리고 카카오미니가 마음을 모아 힐링 콘텐츠를 제작했습니다. 박보영, 한효주, 한지민, 진구, 박성훈 배우가 좋은 글귀를 낭독하고 감상하는 만큼 기부하는 힐링 프로젝트입니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;좋은 글과 좋은 목소리, 거기에 좋은 취지가 더해지니 메마른 감성이라도 어찌 촉촉해지지 않을 수 있을까요.   담담한 시 한 구절이 심심한 위로가 되길 바라며.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/Ezdd0fuOYBg&quot; width=&quot;320&quot; height=&quot;180&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p style=&quot;text-align: center;&quot; data-ke-size=&quot;size14&quot;&gt;&lt;span style=&quot;color: #9d9d9d;&quot;&gt;[영상 1] BH배우들의 셀럽 힐링사운드 녹음 현장&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size14&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/8L5axM2IPUI&quot; width=&quot;320&quot; height=&quot;180&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p style=&quot;text-align: center;&quot; data-ke-size=&quot;size14&quot;&gt;&lt;span style=&quot;color: #9d9d9d;&quot;&gt;[영상 2] 카카오미니 힐링사운드 사용 예&lt;/span&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;span&gt;지친 마음 토닥토닥, AI로운 힐링 생활&lt;/span&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;건강한 정신이 건강한 육체를 만드는 시대. 여러분의 마음은 안녕한가요? 때로 불안과 혐오의 감정에 휩싸이진 않았나요?&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;바깥세상이 어떻든 우린 여전히 일해야 하고, 공부해야 하고, 아이/댕댕이/고영희 등등을 길러야 합니다. 이렇게 바쁜 이들의 집중을 돕고 여유를 선사하는 것이 힐링사운드의 작지만 큰 비전입니다.  &lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;다음 과제는 추가 콘텐츠 확보인데요, 양적 확장보다는 &amp;lsquo;누가, 뭐 할 때, 몇 시쯤&amp;rsquo;과 같은 구체적인 scene을 기반으로 검토 중입니다. &amp;lsquo;음악'처럼 그 자체로&amp;nbsp; 가치 있기보다는 수면, 공부, 휴식을 보조하는 성격이 강하기 때문이죠.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;또 하나는 &amp;lsquo;AI&amp;rsquo;라서 잘할 수 있는 것에 대한 고민입니다. 깨기 힘든 아침, 지친 오후, 잠이 오지 않는 밤&amp;hellip; 지금의 상황과 맥락을 알고, 유저의 취향과 습관을 기억하는 똑똑한 힐링을 다짐하며 글을 마칩니다.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;[참고 기사]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.idaegu.co.kr/news/articleView.html?idxno=312993&quot;&gt;https://www.idaegu.co.kr/news/articleView.html?idxno=312993&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;a href=&quot;https://www.yna.co.kr/view/AKR20191113112600009&quot;&gt;https://www.yna.co.kr/view/AKR20191113112600009&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;a href=&quot;http://www.ciokorea.com/news/156561&quot;&gt;http://www.ciokorea.com/news/156561&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;blob&quot; data-origin-width=&quot;1751&quot; data-origin-height=&quot;1254&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/cxTi6D/btqFSZVL8UK/orRRZFlr3vsACLKb0vUpX0/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/cxTi6D/btqFSZVL8UK/orRRZFlr3vsACLKb0vUpX0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcxTi6D%2FbtqFSZVL8UK%2ForRRZFlr3vsACLKb0vUpX0%2Fimg.png' data-filename=&quot;blob&quot; data-origin-width=&quot;1751&quot; data-origin-height=&quot;1254&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;최예진(Rhea)&lt;/p&gt;
&lt;p class=&quot;desc&quot;&gt;궁금한 게 많아서 먹고 싶은 것도 많은 INFP=조용한 꾸러기=획자 입니다.&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
<category>Tech Log</category>
<category>백색소음</category>
<category>자연의소리</category>
<category>카카오i</category>
<category>카카오엔터프라이즈</category>
<category>카카오엔터프라이즈채용</category>
<category>코로나블루</category>
<category>헤이카카오</category>
<category>힐링명상</category>
<category>힐링사운드</category>
<author>celina.7</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/67</guid>
<comments>https://tech.kakaoenterprise.com/67#entry67comment</comments>
<pubDate>Fri, 28 Aug 2020 10:57:11 +0900</pubDate>
</item>
<item>
<title>현직 개발자가 들려주는 카카오엔터프라이즈</title>
<link>https://tech.kakaoenterprise.com/77</link>
<description>&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&lt;i&gt;&amp;nbsp;&lt;/i&gt;&lt;/b&gt;&lt;b&gt;&lt;i&gt;Why not?&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&lt;i&gt;If Kakao Enterprise, ( )&amp;nbsp;&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;b&gt;시작하며&lt;/b&gt;&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;2021 카카오 공동체 개발자 신입공채 서류접수가 시작됐습니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;카카오엔터프라이즈 역시 역량 있는 신입 개발자 영입을 위해 참여하게 되었는데요.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;카카오엔터프라이즈를 간단하게 소개하자면, 기술 개발을 선도하고 AI 생태계를 이끌어가고자 각 기술 분야의 국내 최고 전문가들이 모여 새롭게 출범한 회사입니다.&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;또한, 저희 크루들은 금융, 유통, 제조, 게임 등 다양한 산업군에 우리의 기술력이 함께할 수 있도록 기술과 산업을 결합하고 새로움을 개척해 나가는 데 열중하고 있답니다.&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;자 그럼, 본격적으로 개발자 신입공채에 대한 이야기를 시작해볼까요? 카카오엔터프라이즈에 지원하고 싶다, 어떤 회사인지 더 알고 싶다! 하시는&amp;nbsp; 여러분들을 위해 카카오엔터프라이즈 개발자 크루들을 상대로 진행한 인터뷰를 공개합니다. 선배 개발자들의 개발 공부 방법, 코딩테스트, 면접 준비 과정 등 다양한 꿀팁들을 보며 카카오엔터프라이즈를 함께 알아보도록 하겠습니다.&amp;nbsp;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #000000;&quot;&gt;카카오엔터프라이즈는 어떤 회사야?&lt;/span&gt;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;jkey.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;540&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/UnPBU/btqG5LIlne4/Gx3vVL2kWDcSGp9FG1JY60/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/UnPBU/btqG5LIlne4/Gx3vVL2kWDcSGp9FG1JY60/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUnPBU%2FbtqG5LIlne4%2FGx3vVL2kWDcSGp9FG1JY60%2Fimg.png' data-filename=&quot;jkey.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;540&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;AI 기술을 선도하는 곳&lt;/span&gt;&lt;/h3&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;ldquo;카카오엔터프라이즈는 카카오의 오랜 노하우를 보유한 AI Lab이 분사해 탄생한 AI 기술 플랫폼 사업자로서, AI 서비스와 챗봇, 클라우드, 기업용 메신저 등 B2B 알짜 아이템을 기반으로 무궁무진한 발전 가능성을 지닌 기업입니다. 특히, 개발자에게 AI와 B2B 서비스를 전담하는 회사는 흔치 않아서 다른 회사에서는 쉽게 경험할 수 없는 개발을 할 수 있다는 점이 큰 장점이에요. AI라는 유망한 분야에 관심을 가진 개발자 그리고 컴퓨터공학 전공생들에게 꼭 추천하고 싶은 회사입니다.&amp;rdquo;&lt;/span&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;가장 개발자답게 일할 수 있는 곳&lt;/span&gt;&lt;/h3&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;&amp;ldquo;대부분의 개발 조직은 자유로운 분위기 속에서 개발자가 하고 싶은 개발을 할 수 있어요! (조직별로 조금씩 차이가 있을 수 있겠지만..) 큰 규모의 기업임에도 개발자가 스스로 기획자처럼 아이디어를 낼 기회가 주어지며, 서비스로서의 가능성이 보인다면 위계나 연차에 구애받지 않고 정식 프로젝트로도 인정받을 수도 있습니다. 그래서 카카오엔터프라이즈의 개발자라면 누구나 개발, 배포 그리고 운영단계까지 다양한 경험을 해볼 수 있죠.&amp;rdquo;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp;&amp;ldquo;기본적으로 개발자 간에 수평적인 문화, 서로를 존중하는 태도, 회사의 적극적인 지원까지 자유롭게 기술을 연구할 수 있는 분위기가 형성되어 있습니다. 개발자로서 커리어를 쌓는 동시에 공부를 병행할 수 있는 기업이 흔치 않기에 더욱 추천하고 싶어요. 한 마디로 개발자가 가장 &amp;ldquo;개발자답게&amp;rdquo; 일할 수 있는 곳이라고 생각합니다. 코로나 이후로는 완전자율근무제도를 적용해서 근무환경도 좋고 업무 능률도 향상되어 개발자의 창의성과 생산성도 높아진 것 같아요. 개발자의 능률을 최대치로 이끌어 내주는 제도와 조직문화가 뒷받침되고 있기 때문에 기술에 대한 관심과 역량만 있다면 누구나 무엇이든 개발할 수 있는 곳이라 생각합니다.&amp;rdquo;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span style=&quot;color: #000000;&quot;&gt;트렌디한 서비스 출시가 가능한 곳&lt;/span&gt;&lt;/h3&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;ldquo;개발된 기술이 아무에게도, 혹은 아무 곳에도 쓰이지 않는다면 의미가 없을 겁니다. 카카오엔터프라이즈는 AI를 연구할 뿐만 아니라 실제 서비스로 발전시켜 사용자에게 직접 닿는 기술을 개발하는 회사입니다. 새로운 사업, 새로운 서비스, 새로운 도전을 통해 실제 사용자의 라이프스타일과 업무 패턴을 변화시키는 일을 할 수 있는 거죠. 최근 IT 산업의 트렌드인 AI와 B2B 사업 두 마리 토끼를 잡은 회사로서, 트렌디한 서비스 출시와 제공을 꿈꾸는 지원자들에게는 더없이 좋은 기회가 될 것입니다.&amp;rdquo;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;&lt;span style=&quot;color: #000000;&quot;&gt;카카오엔터프라이즈에 지원하려면?&lt;/span&gt;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;krew.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;540&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/djnedF/btqG5MgN3EZ/EfRQovHq8K0INoea1Lffwk/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/djnedF/btqG5MgN3EZ/EfRQovHq8K0INoea1Lffwk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdjnedF%2FbtqG5MgN3EZ%2FEfRQovHq8K0INoea1Lffwk%2Fimg.png' data-filename=&quot;krew.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;540&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;라떼는 말이야! 현직자의 지원후기&lt;/span&gt;&lt;/h3&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&quot;지원할 땐 그냥 별생각 없이 지원했는데 &amp;ldquo;if kakao&amp;rdquo; 컨퍼런스에 참석하고 나서는 카카오엔터프라이즈에 꼭 다니고 싶다는 생각이 훨씬 커졌던 기억이 나네요. 개발자들을 위한 행사인 if kakao를 통해 카카오엔터프라이즈의 기술과 문화를 간접적으로 체험해 볼 수 있었는데, 저에게 너무 매력적으로 다가왔습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;제가 개발자 공채를 준비하던 때에는 이전에 면접을 봤던 사람들이 남긴 정보가 많지 않아서 면접 준비하는 과정이 힘들었습니다. 그래서 혼자 최대한 기출 문제를 풀고 코딩테스트 봤던 내용을 리뷰하면서 부족한 점을 채워나갔고요. 동시에 웹사이트, 보도 자료 등을 통해 회사에 대한 정보를 얻으려고 노력하면서 매일 1시간씩 면접 준비를 했습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;아무래도 신입 공채는 경력 채용과 달리 기술적 지식이나 역량보다도 지원자의 마음가짐과 포부를 많이 보셨던 것 같아요. 그리고 이건 진짜 좋다고 느끼는데, 다른 회사보다 전형 별 합격, 불합격 피드백이 빠릅니다.&quot;&lt;/span&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;실전편) 코딩테스트, 어떻게 준비할까?&lt;/span&gt;&lt;/h3&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&quot;이미 많이 들으셨겠지만 무엇보다도 기본기(수학,통계,코딩)에 충실한 것이 중요하다고 생각합니다. 그래야 기술을 외우는 것이 아니라 진정으로 이해하는 것이 가능해지니까요.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;어떤 시험이든 기출 문제를 기반으로 공부하듯이, 코딩테스트도 이전 카카오 코딩테스트 문제를 풀어보면 많은 도움이 됩니다. 꼭 입사가 목적이 아니더라도 학생 때부터 카카오에서 주최하는 코딩테스트에 참여해보는 것도 좋은 경험이 될 것 같아요.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;코딩테스트를 준비하실 때는 국내는 프로그래머스, 해외는 릿코드나 해커랭크를 추천드리는데 다양한 문제 풀이 있어서 기본기 이해에도 도움이 되고요. 또는 백준이나 sw expert 사이트도 이용해서 꾸준히 문제를 푸는 것도 좋습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;평소에 다른 사람들과 스터디를 진행하면서 다양한 문제들에 대해 서로의 생각을 공유하면서 시각을 넓혔던 경험 역시 도움이 되었습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;마지막으로 카카오 코딩테스트는 문제가 많은 편이고 개인마다 체감하는 난이도가 상이해서 순서대로 푸는 것만을 고집할 필요는 없어요. 다만, 코딩테스트를 풀 때 막히더라도 문제를 천천히 읽다보면 생각이 날 수 있으니 시간 잘 확인하면서 포기하지 마시고 끝까지 문제를 풀어보세요. 그러면 답이 조금씩 보입니다!&quot;&lt;/span&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;실전편) 면접, 어떻게 준비할까?&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;recruiting.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;540&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bq6PlD/btqG68CQapn/yAAbv6k4T7bs9SrI5qtDjk/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/bq6PlD/btqG68CQapn/yAAbv6k4T7bs9SrI5qtDjk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbq6PlD%2FbtqG68CQapn%2FyAAbv6k4T7bs9SrI5qtDjk%2Fimg.png' data-filename=&quot;recruiting.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;540&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&quot;개발이나 코딩 관련 알고 있는 지식이나, 기존에 했던 스터디 경험 및 프로젝트를 잘 설명할 수 있도록 반복 연습하는 것이 면접 준비 팁입니다. 프로젝트를 한 것이 있다면 확실히 이해하고 계시면 도움이 되고 또 CS 기초를 튼튼히 다지는 것이 면접 준비의 기본이라고 생각합니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;면접에서 자신의 능력을 어떻게 활용할 것인지 자신 있게 설명하려면 이런 것들이 선행되어야 하거든요. 자신이 했던 프로젝트에서 어떤 기술을 사용했는지 보다는 왜 사용했는지를 근본적으로 아는 것이 중요합니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;개발자들이 기술 면접을 준비해야 할 때는 두 가지가 필요합니다. 첫 번째는 기본적인 인성 면접에 대한 연습입니다. 이 부분은 유튜브에 면접 준비를 검색하면 많은 예시들이 있으니 참고하면 도움이 될 것 같습니다.&amp;nbsp;두 번째는 기술 관련 면접인데, 이는 학교에서 배운 CS 전공 책을 참고해도 좋고, GitHub에 관련 인터뷰 문제들을 모아 놓은 레포지토리가 있으니 참고하는 것도 좋은 방법입니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;그리고 기술 면접을 연습하실 때는 친구와 같이 서로 질문해보고 답변을 리뷰해보면 자신이 뭘 모르는지, 설명은 어떻게 해야 적절한지 등 객관적인 피드백을 받을 수 있어 도움이 많이 될 거예요. 그 외 자신이 겪었던 개발 트러블슈팅에 대해서도 준비해보시는 것도 적극 추천드립니다. 저는 면접 중 제가 직접 수행했던 프로젝트 구조에 대해 화이트보드를 자유롭게 사용하여 설명했었는데요. 미리 예전에 해 본 프로젝트를 다시 살펴보고 자세히 준비했었기 때문에 매끄럽게 답변하며 좋은 점수를 얻을 수 있었던 것 같습니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;특히, 카카오엔터프라이즈 면접은 수동적으로 질문에 대답하는 게 아니라, 주도적으로 제가 한 프로젝트를 전달하고 이에 대한 세부 질문을 주는 형태로 진행되었습니다. 제가 면접을 전반적으로 리드한다는 인상을 받았고, 결과적으로 제 자신을 더 잘 어필할 기회가 되었던 것 같아요.&quot;&amp;nbsp;&lt;b&gt;&lt;/b&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;&lt;span style=&quot;color: #000000;&quot;&gt;2021 지원자들을 위한 응원의 한마디&lt;/span&gt;&lt;/b&gt;&lt;span style=&quot;color: #666666;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;trial.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;166&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/evjP1i/btqG5LVT7h0/cYjl7kyLD22szwbZYzVGG1/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/evjP1i/btqG5LVT7h0/cYjl7kyLD22szwbZYzVGG1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FevjP1i%2FbtqG5LVT7h0%2FcYjl7kyLD22szwbZYzVGG1%2Fimg.png' data-filename=&quot;trial.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;166&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;lily.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;166&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/KZhkc/btqG6gOSW00/LYnKe480tG3vCe6wkJVzJ1/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/KZhkc/btqG6gOSW00/LYnKe480tG3vCe6wkJVzJ1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKZhkc%2FbtqG6gOSW00%2FLYnKe480tG3vCe6wkJVzJ1%2Fimg.png' data-filename=&quot;lily.png&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;166&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;blockquote style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot; data-ke-style=&quot;style2&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt; &lt;span style=&quot;color: #666666;&quot;&gt;&quot;카카오엔터프라이즈에 지원해 함께하게 되실 분들 미리 환영합니다! 여러 단계를 거치는 채용 전형이라 많이 지칠 수도 있지만 마지막까지 힘내서 카카오엔터프라이즈의 크루로서 같이 길을 걸어갈 수 있으면 좋겠습니다.&lt;/span&gt;&lt;/span&gt;&lt;/blockquote&gt;
&lt;blockquote style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot; data-ke-style=&quot;style2&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;&amp;ldquo;업무 분위기가 좋고 업무환경도 잘 갖추어진 회사입니다. 회사 업무를 하면서 자기 자신도 성장시킬 수 있는 곳인 만큼 개인의 성장 가능성을 보고 뽑아주시는 것 같습니다. 주저 없이 지원해주시길 바랍니다!&amp;rdquo;&lt;/span&gt;&lt;/blockquote&gt;
&lt;blockquote style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot; data-ke-style=&quot;style2&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;&amp;ldquo;정말 후회 없는 선택이 될 겁니다. 면접보면 더 입사하고 싶어지고, 일 하다 보면 더 잘하고 싶어지는 회사. 이런 회사 또 없습니다.&amp;rdquo;&lt;/span&gt;&lt;/blockquote&gt;
&lt;blockquote style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot; data-ke-style=&quot;style2&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;&amp;ldquo;코로나로 인해 고민이 크셨을 텐데 열정 있는 모습을 보여주시면 잘 될 거라고 생각합니다. 열심히 준비하신 만큼 좋은 결과 얻으셔서 카카오엔터프라이즈에서 원하는 꿈을 같이 이루면 좋겠습니다!&amp;rdquo;&lt;/span&gt;&lt;/blockquote&gt;
&lt;blockquote style=&quot;text-align: left;&quot; data-ke-size=&quot;size18&quot; data-ke-style=&quot;style2&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;&amp;ldquo;딱 한마디만 드리고 싶어요. 너무 두려워하지 마시고 재밌게 준비하시면 돼요!&amp;rdquo;&lt;/span&gt;&lt;b&gt;&lt;/b&gt;&lt;/blockquote&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;마치며&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;카카오엔터프라이즈 크루들은 당연한 것들에 대해 끊임없이 질문하고 도전하는 자세로 일합니다. AI 기술에 대해 치열하게 고민하고 연구하며, 우리의 기술로 더 나아질 업무와 일상의 변화, 그리고 미래를 그리고 있습니다. 카카오엔터프라이즈와 함께 다양한 기술과 경험, 더 많은 비즈니스와 산업을 새롭게 혁신해 나갈 여러분들과 만나기를 기대합니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;i&gt;&lt;b&gt;&amp;ldquo;카카오엔터프라이즈의 개발자가 되기 위해 도전하시는 여러분들을 응원합니다!!&amp;rdquo;&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&lt;br /&gt;&lt;br /&gt;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;공채.jpg&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;540&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bFmofb/btqHgwbUkks/Es9dJ3f2kAJ3KZkh21XALK/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/bFmofb/btqHgwbUkks/Es9dJ3f2kAJ3KZkh21XALK/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbFmofb%2FbtqHgwbUkks%2FEs9dJ3f2kAJ3KZkh21XALK%2Fimg.jpg' data-filename=&quot;공채.jpg&quot; data-origin-width=&quot;1200&quot; data-origin-height=&quot;540&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;b&gt;&lt;span style=&quot;color: #000000;&quot;&gt;새로운 길에 도전하는 최고의 Krew들과 함께 해요!&lt;/span&gt;&lt;/b&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://www.welcomekakao.com/competitions/317/2021-kakao-blind-recruitment&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2021 KAKAO BLIND RECRUITMENT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;</description>
<category>Krew Talk</category>
<category>개발자</category>
<category>기술선도</category>
<category>면접후기</category>
<category>카카오엔터프라이즈</category>
<category>카카오엔터프라이즈 채용</category>
<category>카카오엔터프라이즈공채</category>
<category>카카오엔터프라이즈면접</category>
<category>카카오엔터프라이즈영입</category>
<category>코딩테스트</category>
<category>크루</category>
<author>렂으</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/77</guid>
<comments>https://tech.kakaoenterprise.com/77#entry77comment</comments>
<pubDate>Mon, 24 Aug 2020 09:59:55 +0900</pubDate>
</item>
<item>
<title>GroupFace: Learning Latent Groups and Constructing Group-based Representations for Face Recognition</title>
<link>https://tech.kakaoenterprise.com/70</link>
<description>&lt;h2 data-ke-size=&quot;size26&quot;&gt;시작하며&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;카카오엔터프라이즈 AI Lab(김용현, 노명철, 신종주)이 카카오(박원표)와 공동으로 쓴 논문 &amp;lsquo;&lt;a href=&quot;http://openaccess.thecvf.com/content_CVPR_2020/html/Kim_GroupFace_Learning_Latent_Groups_and_Constructing_Group-Based_Representations_for_Face_CVPR_2020_paper.html&quot;&gt;GroupFace: Learning Latent Groups and Constructing Group-based Representations for Face Recognition&lt;/a&gt;&amp;rsquo;이 컴퓨터 비전 및 패턴 인식 컨퍼런스(CVPR)에 실렸습니다. CVPR는 컴퓨터 비전과 패턴 인식 분야의 논문을 발표하는 세계 최대 규모의 학술 대회로, IEEE(Institute of Electrical and Electronics Engineers)와 CVF(Computer Vision Foundation)가 공동 주최합니다. 올해 CVPR에는 접수된 논문 중 25%인 1,470편이 통과됐습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;이번 논문에서 AI Lab은 얼굴 인식에 전문화된 새로운 아키텍처인 GroupFace를 제안했습니다. GroupFace는 얼굴의 유사성을 그룹화해 표현하는 여러 개의 특징 벡터(group-aware representation)를 적용해 모델의 표현력을 높였습니다. 사람의 개입 없이도 각 그룹에 속하는 샘플 수의 균형을 맞추는 Self-distributed Label 기법도 적용했습니다. 그 결과, 제안된 방법은 1:1 얼굴 검증과 1:N 얼굴 인식 작업에서 최소한의 추가 연산만으로 여러 데이터셋에 대해 현재 최고 수준의(SOTA) 성능을 얻을 수 있었습니다. AI Lab은 이번 연구로 얻은 기술력과 경험을 바탕으로 자사 얼굴 엔진 기술을 고도화한다는 계획입니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;div style=&quot;position: relative; max-width: 100%; padding-bottom: 56.25%; height: 0;&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/7jAvwA7Z9KM&quot; width=&quot;320&quot; height=&quot;180&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;Abstract&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;In the field of face recognition, a model learns to distinguish millions of face images with fewer dimensional embedding features, and such vast information may not be properly encoded in the conventional model with a single branch. We propose a novel face-recognition-specialized architecture called GroupFace that utilizes multiple group-aware representations, simultaneously, to improve the quality of the embedding feature. The proposed method provides self-distributed labels that balance the number of samples belonging to each group without additional human annotations, and learns the group-aware representations that can narrow down the search space of the target identity. We prove the effectiveness of the proposed method by showing extensive ablation studies and visualizations. All the components of the proposed method can be trained in an end-to-end manner with a marginal increase of computational complexity. Finally, the proposed method achieves the state-of-the-art results with significant improvements in 1:1 face verification and 1:N face identification tasks on the following public datasets: LFW, YTF, CALFW, CPLFW, CFP, AgeDB-30, MegaFace, IJB-B and IJB-C.&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;Overall Architecture&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;We introduce a new face recognition-specialized architecture that integrates the group-aware representations into the embedding feature and provides well-distributed group-labels to improve the quality of feature representation.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;The rationale behind the effectiveness of GroupFace can summarize in two main ways:&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;(1) It is well known that additional supervisions from different objectives can bring an improvement of the given task by sharing a network for feature extraction, e.g., a segmentation head can improve accuracy in object detection. Likewise, learning the groups can be a helpful cue to train a more generalized feature extractor for face recognition.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;(2) GroupFace proposes a novel structure that fuses instance-based representation and group-based representation, which is empirically proved its effectiveness.&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;Our GroupFace can be applied to many existing face recognition methods to obtain a significant improvement with a marginal increase in the resources. Especially, a hard-ensemble version of GroupFace can achieve high recognition-accuracy by adaptively using only a few additional convolutions.&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;794&quot; height=&quot;233&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/cV2PNx/btqGbPyWoJy/EJmVNApnWevPUddUG6dCT1/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/cV2PNx/btqGbPyWoJy/EJmVNApnWevPUddUG6dCT1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcV2PNx%2FbtqGbPyWoJy%2FEJmVNApnWevPUddUG6dCT1%2Fimg.png' width=&quot;794&quot; height=&quot;233&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size14&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;[ Figure 1 ] GroupFace generates a shared feature of 4096 dimension and deploys a fully-connected layer for an instance-based representation $\mathbf{v}_{\mathbf{x}}$ and $K$ fully-connected layers for group-aware representations $\mathbf{v}_{\mathbf{x}}^{{G}}$ for a given sample $\mathbf{x}$. A group-decision-network, which is supervised by the self-distributed labeling, outputs a set of group probabilities $\left\{ p(G_0|\mathbf{x}), p(G_1|\mathbf{x}), ..., p(G_{K-1}|\mathbf{x}) \right\} $ from the instance-based representation. The final representation of 512 dimension is an aggregation of the instance-based representation and the weighted sum $\mathbf{v}_{\mathbf{x}}^{{G}}$ of the group-aware representations with the group probabilities. W is a weight of the function $g$.&lt;/span&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;Experiments&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;To show the effectiveness of our GroupFace, we evaluate the proposed method on various public datasets and achieve the state-of-the-arts accuracy on all of the datasets. We also perform the extensive ablation studies on the it&amp;rsquo;s behaviors.&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;1. Experimental Results&lt;/h3&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;776&quot; height=&quot;140&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/JbUpl/btqGfaVGRUh/OaulxgTvhpnZcaBKnbWZY0/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/JbUpl/btqGfaVGRUh/OaulxgTvhpnZcaBKnbWZY0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJbUpl%2FbtqGfaVGRUh%2FOaulxgTvhpnZcaBKnbWZY0%2Fimg.png' width=&quot;776&quot; height=&quot;140&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size14&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;[Table 1] Evaluation on LFW, YTF, CALFW, CPLFW, CFP-FP, AgeDB-30 and MegaFace.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;775&quot; height=&quot;218&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bJxly3/btqGev6SkRY/DLS8QSqBpikbhRwvjwIZk1/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/bJxly3/btqGev6SkRY/DLS8QSqBpikbhRwvjwIZk1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbJxly3%2FbtqGev6SkRY%2FDLS8QSqBpikbhRwvjwIZk1%2Fimg.png' width=&quot;775&quot; height=&quot;218&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size14&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;[Table 2] Evaluation according to different FARs on IJB-B and IJB-C. Our GroupFace is trained by ArcFace. &amp;dagger; denotes that a model is evaluated by using the group-aware similarity.&lt;/span&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;2. Ablation Studies&lt;/h3&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;352&quot; height=&quot;405&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bfo1wS/btqGbNA4aGO/hzyW7zl1PRkzqHIDTKF0wK/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/bfo1wS/btqGbNA4aGO/hzyW7zl1PRkzqHIDTKF0wK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbfo1wS%2FbtqGbNA4aGO%2FhzyW7zl1PRkzqHIDTKF0wK%2Fimg.png' width=&quot;352&quot; height=&quot;405&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;figure class='imageblock alignCenter' width=&quot;347&quot; height=&quot;405&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/ctP2W8/btqGdtWphJA/rfCbeZY9LkfK4mkTDzOoh0/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/ctP2W8/btqGdtWphJA/rfCbeZY9LkfK4mkTDzOoh0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FctP2W8%2FbtqGdtWphJA%2FrfCbeZY9LkfK4mkTDzOoh0%2Fimg.png' width=&quot;347&quot; height=&quot;405&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size14&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;[Table 3] Ablation studies for the proposed GroupFace on IJB-B dataset. The baseline is a recognition-model trained by ArcFace and &amp;dagger; denotes an evaluation procedure using the group-aware similarity.&lt;/span&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;Visualization&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;The trained latent groups are not always visually distinguishable because they are categorized by a non-linear function of GDN using a latent feature, not a facial attribute (e.g., hair, glasses, and mustache). However, there are two cases of groups (Group 5 and 20) that we can clearly see their visual properties; 95 of randomly-selected 100 images are men in Group 5 and 94 of randomly-selected 100 images are bald men in Group 20. Others are not described as an one visual property, however, they seems to be described as multiple visual properties such as smile women, right-profile people and scared people in Group 1.&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;788&quot; height=&quot;222&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/JgyXh/btqGdRP4W7v/0OXbsvLBrc6KFKZ7OLaq80/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/JgyXh/btqGdRP4W7v/0OXbsvLBrc6KFKZ7OLaq80/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJgyXh%2FbtqGdRP4W7v%2F0OXbsvLBrc6KFKZ7OLaq80%2Fimg.png' width=&quot;788&quot; height=&quot;222&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size14&quot;&gt;&lt;span style=&quot;color: #666666;&quot;&gt;[Figure 2] Example images belonging to each groups. As enormous identities (80k~) of large scale dataset cannot be mapped to a few groups (32), each group contains identities of multiple characteristics. Some groups have one common visual description with some variations while others have multi-mode visual descriptions.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/d9t5FY/btqGe6MJZYK/f1wHgZkSSCYURc5mavBPKK/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/d9t5FY/btqGe6MJZYK/f1wHgZkSSCYURc5mavBPKK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fd9t5FY%2FbtqGe6MJZYK%2Ff1wHgZkSSCYURc5mavBPKK%2Fimg.png' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;김용현(aiden)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;대학원에서 물체 검출 및 얼굴 인식을 연구하고, 현재 카카오 엔터프라이즈에서는 얼굴 인식 연구를 담당하고 있습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;253&quot; height=&quot;253&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/drTX03/btqGew5LZsd/uqrjBnCJf2g31J8o2a4RL0/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/drTX03/btqGew5LZsd/uqrjBnCJf2g31J8o2a4RL0/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdrTX03%2FbtqGew5LZsd%2FuqrjBnCJf2g31J8o2a4RL0%2Fimg.jpg' width=&quot;253&quot; height=&quot;253&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;박원표(tony)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;데이터 사이언스에 관심이 생겨 덜컥 인공지능 관련 석사 과정에 진학했습니다. 카카오에서는 인공지능을 이용한 이미지처리된 연구와 개발을 맡고 있습니다. 이번 생에는 사람만큼 똑똑한 인공지능의 탄생을 꼭 보고 싶습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;260&quot; height=&quot;260&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/dKHCrS/btqGe8cIpNS/jqOqQ0DKET94E7zYMBoHO0/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/dKHCrS/btqGe8cIpNS/jqOqQ0DKET94E7zYMBoHO0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdKHCrS%2FbtqGe8cIpNS%2FjqOqQ0DKET94E7zYMBoHO0%2Fimg.png' width=&quot;260&quot; height=&quot;260&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;노명철(joshua)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;카카오엔터프라이즈에서 훌륭한 동료들과 함께 얼굴 인식 관련 기술을 연구∙개발하고 있습니다. 기계의 성능 수치보다는, 사람의 행복 지수를 높이는 인공지능 기술을 만들고 싶습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/b3EduJ/btqGe7x6YN0/KVfOWgXUB9KXnbGHfibYwk/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/b3EduJ/btqGe7x6YN0/KVfOWgXUB9KXnbGHfibYwk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb3EduJ%2FbtqGe7x6YN0%2FKVfOWgXUB9KXnbGHfibYwk%2Fimg.png' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;신종주(isaac)&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;대학원에서 얼굴 특징점 검출을 전공한 뒤, 현재는 카카오엔터프라이즈에서 얼굴 영상과 관련된 연구 개발 조직을 맡고 있습니다. 연구 중인 얼굴 인식이 앞으로 제 두 아들이 살아갈 세상에 도움이 되었으면 좋겠습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
<category>AI Research</category>
<category>AI Lab</category>
<category>cvpr</category>
<category>GroupFace</category>
<category>ResNet</category>
<category>멀티미디어처리파트</category>
<category>얼굴 인식</category>
<category>카카오엔터프라이즈</category>
<author>samantha.her</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/70</guid>
<comments>https://tech.kakaoenterprise.com/70#entry70comment</comments>
<pubDate>Tue, 18 Aug 2020 13:15:16 +0900</pubDate>
</item>
<item>
<title>AI에게 어떻게 음성을 가르칠까?</title>
<link>https://tech.kakaoenterprise.com/66</link>
<description>&lt;h2 data-ke-size=&quot;size26&quot;&gt;시작하며&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;인간은 귀로 듣고, 입으로 말하여 타인과 의사소통합니다. 나와 대화할 수 있는 존재를 창조하고 싶다는 바람은 많은 사람들이 오래전부터 상상하고, 소설로 쓰고, 연구해 왔습니다. 오늘날 그 바람은 음성을 듣고 정보를 이해하고, 음성을 만들어 정보를 전달하는 대화형 인공지능(Artificial Intelligence, 이하 AI)의 시대가 도래하게 됨으로써 그 결실을 맺었습니다. 기계가 사람의 음성을 듣는 음성인식(Speech recognition)은 AI의 귀이고, 기계가 사람의 음성으로 말하는 음성합성(Speech synthesis)은 AI의 입이라고 할 수 있습니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;하지만 AI가 음성을 이해하고, 활용할 수 있도록 가르치는 것은 쉽지 않은 일입니다. 사람이 몇 초면 만들 수 있는 음성 한 문장에는 너무나 많은 정보가 숨겨져 있으며, 다양한 목적을 가진 AI를 만들기 위해서는 각각 그 목적에 필요한 음성 정보를 이해하도록 가르쳐야 하기 때문입니다. 따라서 음성을 다루는 AI를 만들려는 개발자는 무엇보다 그 자신이 음성에 대해 잘 알고 있어야 합니다. 이번 글에서는 사람이 말하고 듣는 음성 한 문장에 어떤 정보들이 들어가 있는지, 이것들이 어떻게 AI를 가르치는 데 사용되는지를 최대한 수식을 배제한 채 키워드 위주로 설명하고자 합니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;음성의 숨은 정보를 찾아내야 하는 이유&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;인간은 다양한 감각 기관을 사용해 외부로부터 오감(五感)을 인지해 정보를 입력받을 수 있습니다. 그중에서도 제일 자주 사용되는 시각과 청각은 가장 효과적으로 정보를 입력받을 수 있는 감각입니다. 하지만 같은 정보를 담고 있을지라도 음성은 이미지와는 그 형태가 매우 다르며, 이를 인지하기 위한 인간의 귀도 눈과는 완전히 다른 방식으로 동작합니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;가령 &amp;lsquo;헤이카카오&amp;rsquo;라는 정보가 담긴 이미지와 음성이 [그림 1]과 같이 주어졌다고 가정해봅시다. 왼쪽 이미지를 보면 사람은 어떤 문장이 적혀있는지를 쉽게 인지할 수 있습니다. 하지만 음성 파형은 눈으로 봐도 어느 부분이 어떤 단어를 의미하는지를 알 수 없습니다. 이는 컴퓨터의 입장에서도 마찬가지인데요. 같은 문장을 한 사람이 여러 번 발음해도 음성 파형의 값을 비교해보면 그 분포가 제각기 매우 다르기 때문입니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;그림1.png&quot; data-origin-width=&quot;2724&quot; data-origin-height=&quot;576&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/c5YNer/btqFHpr5Oab/5etnHpALQL5pE9CFqjXOX0/img.png' data-lightbox='lightbox' data-alt='[그림 1] &amp;amp;lsquo;헤이 카카오&amp;amp;rsquo;가 적힌 이미지와 음성 파형'&gt;&lt;img src='https://blog.kakaocdn.net/dn/c5YNer/btqFHpr5Oab/5etnHpALQL5pE9CFqjXOX0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc5YNer%2FbtqFHpr5Oab%2F5etnHpALQL5pE9CFqjXOX0%2Fimg.png' data-filename=&quot;그림1.png&quot; data-origin-width=&quot;2724&quot; data-origin-height=&quot;576&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 1] &amp;lsquo;헤이 카카오&amp;rsquo;가 적힌 이미지와 음성 파형&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;음성에 들어있는 정보(발음의 종류, 성별, 음색, 높이 등)는 음성 신호 자체에서 쉽사리 얻어낼 수 없고, 수학적인 신호 처리를 거쳐야만 추출할 수 있습니다. 그중 대표적인 한 가지로, 음성을 주파수(frequency, 단위: Hertz)라는 또 다른 축으로 관측하는 방법이 있는데요. 주파수란 신호가 1초에 몇 번 진동했는지를 나타내는 수치이며, 소리는 빠르게 진동할수록, 즉 주파수가 높을수록 음이 높게 들립니다. 자연에서 들을 수 있는 모든 소리는 다양한 주파수 성분들의 합으로 이루어져 있습니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;푸리에 변환(Fourier transform)이라는 함수를 사용하면 특정 시간 길이의 음성 조각(이를 프레임이라고 부름)이 각각의 주파수 성분들을 얼마만큼 갖고 있는지를 의미하는 스펙트럼(spectrum)을 얻을 수 있습니다. 이렇게 음성 전체로부터 얻은 여러 개의 스펙트럼을 시간 축에 나열하면 시간 변화에 따른 스펙트럼의 변화인 스펙트로그램(spectrogram)을 얻게 됩니다. 사람의 귀 또한 이와 유사한 메커니즘을 갖고 있어 소리에 들어 있는 각각의 주파수 성분들을 추출하는 방식으로 청취한 소리에 내재된 정보들을 얻는 것입니다.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;그림2.png&quot; data-origin-width=&quot;1872&quot; data-origin-height=&quot;827&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/czu8qs/btqFEj7Jg4p/pvKjprTonYQXJccbT5YKqk/img.png' data-lightbox='lightbox' data-alt='[그림 2] &amp;amp;lsquo;이&amp;amp;rsquo; 발음에 해당하는 스펙트럼(왼쪽) 과 &amp;amp;lsquo;헤이 카카오&amp;amp;rsquo; 음성에서 추출한 스펙트로그램(오른쪽)'&gt;&lt;img src='https://blog.kakaocdn.net/dn/czu8qs/btqFEj7Jg4p/pvKjprTonYQXJccbT5YKqk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fczu8qs%2FbtqFEj7Jg4p%2FpvKjprTonYQXJccbT5YKqk%2Fimg.png' data-filename=&quot;그림2.png&quot; data-origin-width=&quot;1872&quot; data-origin-height=&quot;827&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 2] &amp;lsquo;이&amp;rsquo; 발음에 해당하는 스펙트럼(왼쪽) 과 &amp;lsquo;헤이 카카오&amp;rsquo; 음성에서 추출한 스펙트로그램(오른쪽)&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;사실, 음성을 처리하는 데에는 수많은 문제가 존재합니다. 이를 해결하기 위해서는 인간이 음성을 만드는 과정과 소리를 듣는 과정을 좀 더 깊게 이해할 필요가 있습니다. 이러한 과정들을 수학적으로 모델링하여 음성의 정보를 추출하거나 필요에 따라 가공할 수 있고, 또 이렇게 얻어낸 수치들인 특징 벡터(feature vector)를 통해 AI가 음성을 이해하도록 가르칠 수 있습니다.&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;음성이 만들어지는 과정&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;발음을 결정하는 소리의 최소 단위인 음소(phoneme)는 크게 2가지로 구분할 수 있는데, 발성할 때 성대(vocal cord)의 진동을 동반하는 유성음(voiced)과 진동 없이 성대를 통과하는 무성음(unvoiced)이 있습니다.(출처: &lt;a href=&quot;https://100.daum.net/encyclopedia/view/14XXE0043017&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;다음백과&lt;/a&gt;)&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;사람의 발성 구조를 공학적으로 해석할 때, 성대를 막 통과한 소리를 여기 신호(excitation signal)라고 부릅니다. 이때 유성음 여기 신호의 파형은 준주기성(quasi-periodic)을 띄게 되며, 성대의 진동 속도에 따라 고유의 기본 주파수(fundamental frequency)와 기본 주파수의 배수에 해당하는 여러 배음(harmonics)들로 전체 스펙트럼이 구성됩니다. 반면, 무성음 여기 신호의 파형은 성대가 진동하지 않아 다양한 주파수 성분이 고르게 포함된 백색소음(white noise)과 같은 스펙트럼을 갖습니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse; width: 100%;&quot; border=&quot;1&quot; data-ke-style=&quot;style12&quot;&gt;&lt;caption&gt;[표 1] 음소의 종류 및 여기 신호의 형태&lt;/caption&gt;
&lt;tbody&gt;
&lt;tr style=&quot;height: 54px;&quot;&gt;
&lt;td style=&quot;height: 20px; text-align: center;&quot;&gt;
&lt;p&gt;종류&lt;/p&gt;
&lt;/td&gt;
&lt;td style=&quot;height: 20px; text-align: center;&quot;&gt;
&lt;p&gt;예시&lt;/p&gt;
&lt;/td&gt;
&lt;td style=&quot;height: 20px; text-align: center;&quot;&gt;
&lt;p&gt;여기 신호의 모델링&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 103px;&quot;&gt;
&lt;td style=&quot;height: 103px; text-align: center;&quot;&gt;
&lt;p&gt;유성음(Voiced)&lt;/p&gt;
&lt;/td&gt;
&lt;td style=&quot;height: 103px; text-align: center;&quot;&gt;
&lt;p&gt;모든 모음&lt;/p&gt;
&lt;p&gt;(/a/, /e/, /i/, &amp;hellip;)&lt;/p&gt;
&lt;/td&gt;
&lt;td style=&quot;height: 103px; text-align: center;&quot;&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;표1-1.png&quot; data-origin-width=&quot;418&quot; data-origin-height=&quot;291&quot; width=&quot;200&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/c31G4U/btqFGybNcOA/TvtPQji3PUtAarI9K01ij0/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/c31G4U/btqFGybNcOA/TvtPQji3PUtAarI9K01ij0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc31G4U%2FbtqFGybNcOA%2FTvtPQji3PUtAarI9K01ij0%2Fimg.png' data-filename=&quot;표1-1.png&quot; data-origin-width=&quot;418&quot; data-origin-height=&quot;291&quot; width=&quot;200&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;
&lt;p&gt;Quasi-periodic signal&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 78px;&quot;&gt;
&lt;td style=&quot;height: 78px; text-align: center;&quot;&gt;
&lt;p&gt;무성음(Unvoiced)&lt;/p&gt;
&lt;/td&gt;
&lt;td style=&quot;height: 78px; text-align: center;&quot;&gt;
&lt;p&gt;대부분의 자음&lt;/p&gt;
&lt;p&gt;(/p/, /t/, /k/, ...)&lt;/p&gt;
&lt;/td&gt;
&lt;td style=&quot;height: 78px; text-align: center;&quot;&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;표1-2.png&quot; data-origin-width=&quot;418&quot; data-origin-height=&quot;291&quot; width=&quot;200&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/cI28Kh/btqFGyQqonf/RoypbP2LUvV1chDH2SRVUK/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/cI28Kh/btqFGyQqonf/RoypbP2LUvV1chDH2SRVUK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcI28Kh%2FbtqFGyQqonf%2FRoypbP2LUvV1chDH2SRVUK%2Fimg.png' data-filename=&quot;표1-2.png&quot; data-origin-width=&quot;418&quot; data-origin-height=&quot;291&quot; width=&quot;200&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;
&lt;p&gt;White noise&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;[그림 3]은 사람이 음성을 만들 때 사용하는 기관들의 동작과 이들을 각각 공학적으로 모델링한 특징 정보들의 관계를 나타냅니다. 처음 폐에서 만드는 압축된 공기는 백색소음에 가까운 비주기성(aperiodicity) 신호로, 정규분포와 같이 쉽게 사용할 수 있는 확률분포로 모델링할 수 있습니다. 성대를 통과한 직후의 여기 신호는 유성음/무성음 여부에 따라 구분되며, 유성음의 경우 기본 주파수 등의 특징을 담고 있습니다. 이후 목, 코, 입, 혀 등의 성도(vocal tract)를 통과하며 발음이 결정되는데, 발음마다 성도의 구조가 달라져 증폭되는 주파수 대역과 감쇠되는 대역 역시 달라지게 됩니다. 이를 스펙트럼 포락선(spectral envelope)이라고 하며, 발음의 종류를 결정하는 주요한 특징으로 꼽힙니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;이렇게 각 발성 기관의 동작을 공학적으로 모델링하고, 각 특징들을 추출, 변환, 예측하는 기술이 음성압축(speech coding), 음성변환(voice conversion), 음성합성(speech synthesis) 등의 영역에 적용되어 연구 개발되어 왔습니다.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;그림3.png&quot; data-origin-width=&quot;1943&quot; data-origin-height=&quot;810&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/b8qgS3/btqFGw6xKnj/Gl7IHOLQYDlD8Eb1m4itb0/img.png' data-lightbox='lightbox' data-alt='[그림 3] 사람의 발성 구조를 공학적으로 모델링한 그림'&gt;&lt;img src='https://blog.kakaocdn.net/dn/b8qgS3/btqFGw6xKnj/Gl7IHOLQYDlD8Eb1m4itb0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb8qgS3%2FbtqFGw6xKnj%2FGl7IHOLQYDlD8Eb1m4itb0%2Fimg.png' data-filename=&quot;그림3.png&quot; data-origin-width=&quot;1943&quot; data-origin-height=&quot;810&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 3] 사람의 발성 구조를 공학적으로 모델링한 그림&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2&gt;음성을 듣는 과정&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;사람이 소리를 듣는 과정을 살펴보면 다음과 같습니다. 소리를 듣는 기관인 귀는 귓바퀴에서 소리를 모으고, 고막과 이소골이 진동하여 달팽이관의 청각 세포를 자극하면 전기 신호가 발생해 이를 뇌에 전달하는 방식으로 동작합니다.(출처: &lt;a href=&quot;https://100.daum.net/encyclopedia/view/129XXXB000126&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;다음백과&lt;/a&gt;)달팽이관은 마치 길게 늘어진 관을 돌돌 말은 모양과 같으며, 액체로 가득 차 있는 이 관에는 청각 세포들이 일렬로 나열해 있는 코르티 기관이 존재합니다. 밖에서 진동이 전달되면 코르티 기관의 특정 청각 세포가 자극되어 전기 신호를 발생시키는데, 청각 세포마다 인지할 수 있는 주파수 대역이 다릅니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://www.britannica.com/science/ear/Transmission-of-sound-within-the-inner-ear&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[그림 4]&lt;/a&gt;를 보면 달팽이관의 가장 안쪽 청각 세포는 저주파 대역을 인지하며, 바깥쪽 청각 세포는 고주파 대역을 인지한다는 점을 알 수 있습니다. 중요한 점은 모든 주파수 대역을 같은 비중으로 인지하지 않고, 고주파에서 저주파로 내려갈수록 담당하는 주파수 대역이 점점 더 조밀해진다는 점입니다. 실제로 고주파 대역보다는 저주파 대역에 소리의 의미 있는 정보가 집중되어 있음을 생각한다면, 이미 인간의 청각 구조는 보다 중요한 음성 정보에 더 집중해서 들을 준비가 되어있다는 점을 알 수 있습니다.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;그림4.jpg&quot; data-origin-width=&quot;600&quot; data-origin-height=&quot;336&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/0aeeB/btqFDa4Lu2t/MsUuUyyodvkIkQ8tyV0l2k/img.jpg' data-lightbox='lightbox' data-alt='[그림 4] 달팽이관의 주파수 별 청각 인지 구조를 모델링한 그림 (출처: Encyclopedia Britannica)'&gt;&lt;img src='https://blog.kakaocdn.net/dn/0aeeB/btqFDa4Lu2t/MsUuUyyodvkIkQ8tyV0l2k/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F0aeeB%2FbtqFDa4Lu2t%2FMsUuUyyodvkIkQ8tyV0l2k%2Fimg.jpg' data-filename=&quot;그림4.jpg&quot; data-origin-width=&quot;600&quot; data-origin-height=&quot;336&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 4] 달팽이관의 주파수 별 청각 인지 구조를 모델링한 그림 (출처: Encyclopedia Britannica)&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;멜 스케일(이하 Mel scale)은 실제 주파수 정보를 인간의 청각 구조를 반영하여 수학적으로 변환하기 위한 대표적인 방법입니다. 높이가 다른 2개의 음을 사람에게 들려줬을 때, 사람이 인지하는 차이와 두 음의 실제 주파수 차이를 다양하게 조사하여 통계가 구축되었고, 이를 대략적으로 따라가는 간단한 함수로 두 단위 간의 관계가 정의되었습니다.(출처: &lt;a href=&quot;https://en.wikipedia.org/wiki/Mel_scale&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;Wikipedia&lt;/span&gt;&lt;/a&gt;) Mel Scale은 주파수 성분을 중요도에 따라 차등적으로 사용하기 위한 좋은 지표로써 다양한 음성처리 분야에서 사용되고 있습니다.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;그림5.png&quot; data-origin-width=&quot;675&quot; data-origin-height=&quot;320&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/2hJpi/btqFFUfv8Cr/l6fvW2KKFbEtEXygmgp8T1/img.png' data-lightbox='lightbox' data-alt='[그림 5] Mel scale과 Hertz scale간의 비교 (출처: Wikipedia)'&gt;&lt;img src='https://blog.kakaocdn.net/dn/2hJpi/btqFFUfv8Cr/l6fvW2KKFbEtEXygmgp8T1/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2hJpi%2FbtqFFUfv8Cr%2Fl6fvW2KKFbEtEXygmgp8T1%2Fimg.png' data-filename=&quot;그림5.png&quot; data-origin-width=&quot;675&quot; data-origin-height=&quot;320&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 5] Mel scale과 Hertz scale간의 비교 (출처: Wikipedia)&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;AI에게 음성을 가르치려면?&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;가장 간단한 예시로 목소리의 성별을 분류하는 모델을 만들고 싶다고 한다면, 목소리의 높이 정보가 담겨있는 기본 주파수를 사용하여 중간에 기준선을 긋는 것만으로도 어느 정도 분류 정확도를 얻을 수 있을 것입니다. 하지만 음성처리에는 음성인식, 음성합성, 화자인식, 분류 등 훨씬 풀기 어려운 연구 분야들이 존재하며, 이들을 해결하기 위해서는 우선 음성의 어떤 정보를 사용해야 하는지를 최우선으로 고민해야 합니다. 대표적으로 음성을 문장으로 변환하는 음성인식 모델을 만들려면 화자가 누구든 상관없이 문장을 동일하게 인식해야 하므로 기본 주파수와 같이 화자에 종속적인 정보보다는 발음 정보와 같은 것이 더 중요합니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;Mel-Frequency Cepstral Coefficient(MFCC)는 음성인식 영역에서 대표적으로 사용되는 특징 벡터입니다. MFCC를 추출하는 과정은 다음과 같습니다.(출처: &lt;a href=&quot;https://en.wikipedia.org/wiki/Mel-frequency_cepstrum&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;Wikipedia&lt;/span&gt;&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote data-ke-style=&quot;style3&quot;&gt;1. &amp;nbsp; 전체 오디오 신호를 일정 간격으로 나누고 푸리에 변환을 거쳐 스펙트로그램을 구합니다.&lt;br /&gt;2.&amp;nbsp; 각 스펙트럼의 제곱인 파워 스펙트로그램에 Mel scale filter bank를 사용해 차원 수를 줄입니다.&lt;br /&gt;3.&amp;nbsp; cepstral 분석을 적용해 MFCC를 구합니다.&lt;/blockquote&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;Cepstral 분석은 푸리에 변환을 거쳤을 때 시간 축에서 천천히 변하는 정보가 낮은 주파수 성분에 위치하고, 빨리 변하는 정보가 높은 주파수 성분에 위치한다는 점에 착안한 방법입니다.(출처: &lt;a href=&quot;https://en.wikipedia.org/wiki/Cepstrum&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;Wikipedia&lt;/span&gt;&lt;/a&gt;) 주파수 축에서 다시 한번 푸리에 변환을 사용하면 천천히 변하는 스펙트럼 포락선 정보는 낮은 성분에 위치하고, 빨리 변하는 여기 신호 정보는 높은 성분에 위치하게 되어, 적절한 취사선택을 통해 원하는 정보가 내재된 특징 벡터를 만들 수 있습니다.&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;그림6.png&quot; data-origin-width=&quot;881&quot; data-origin-height=&quot;249&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bVwXdw/btqFFU7FxE6/ln7SEzlM74NTKJCzyNkQpk/img.png' data-lightbox='lightbox' data-alt='[그림 6] Mel scale filter bank의 예시 (출처: 개인 블로그)'&gt;&lt;img src='https://blog.kakaocdn.net/dn/bVwXdw/btqFFU7FxE6/ln7SEzlM74NTKJCzyNkQpk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbVwXdw%2FbtqFFU7FxE6%2Fln7SEzlM74NTKJCzyNkQpk%2Fimg.png' data-filename=&quot;그림6.png&quot; data-origin-width=&quot;881&quot; data-origin-height=&quot;249&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 6] Mel scale filter bank의 예시 (출처: 개인 블로그)&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;MFCC를 계산하는 과정은 다소 복잡하지만, 그만큼 효과적인 음성 정보를 추출해 낼 수 있습니다. 인간의 청각 구조를 반영한 Mel scale 기반 filter bank&lt;a href=&quot;https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[그림 6]&lt;/a&gt;를 사용하여 효율적으로 특징을 압축할 수 있고, cepstral 분석을 통해 음성인식에 필요한 발음 특성을 스펙트럼 포락선 정보로 구할 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;이외에도 MFCC와 비슷한 접근법의 Linear Predictive Coding(LPC), Perceptual Linear Prediction(PLP) 등 다양한 방법론이 존재하고, 음성의 시간 축 변화를 좀 더 반영하기 위해 앞서 설명한 값들의 1차, 2차 미분값(delta, delta-delta)을 추가하기도 하며, 성능 향상을 위해 zero crossing rate(ZCR), energy 등을 사용하기도 합니다. 이처럼 음성 특징 벡터의 종류가 다양하므로, 학습하려는 모델에 알맞는 특징을 적절히 선택하는 것이 중요합니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;최근에는 하드웨어의 발달로 연산 속도와 메모리 용량이 충분히 증가했고, Deep Neural Network(DNN)에 대한 연구가 매우 활발히 이루어지면서 복잡한 음성 도메인 지식의 요구가 최소화된 End-to-End(E2E) 방식 모델의 연구가 주목받고 있습니다. 아직 음성 파형 그대로를 입력받는 완전한 E2E 방식은 성능 및 메모리 측면에서 갈 길이 멀지만, 최소한의 특징 벡터를 사용할 수 있어 다양한 분야에서 기존의 전통적인 음성 모델들의 성능을 빠르게 추격하거나 심지어 뛰어넘고 있습니다.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;카카오엔터프라이즈의 AI 음성처리 서비스 소개&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;카카오의 인공지능 플랫폼 Kakao i에는 사용자를 위한 다양한 AI 서비스가 반영되어 있습니다. 지금부터 카카오엔터프라이즈의 음성처리 기술이 탑재된 Kakao i 음성 엔진에 대해 간단히 소개하고자 합니다.&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;음성인식&lt;/h3&gt;
&lt;figure data-ke-type=&quot;video&quot; data-ke-style=&quot;alignCenter&quot; data-video-host=&quot;kakaotv&quot; data-video-url=&quot;https://tv.kakao.com/channel/2743187/cliplink/393114614&quot; data-video-thumbnail=&quot;https://scrap.kakaocdn.net/dn/JUnuZ/hyGK4HdIkH/lf42mVjiCiBVqTl9nSfBLk/img.png?width=854&amp;amp;height=479&amp;amp;face=0_0_854_479,https://scrap.kakaocdn.net/dn/dPuTuC/hyGK2bytJG/P25GY2KPK4KTYo0nJWKQAK/img.jpg?width=640&amp;amp;height=360&amp;amp;face=0_0_640_360&quot; data-video-width=&quot;854&quot; data-video-height=&quot;479&quot; data-ke-mobilestyle=&quot;widthContent&quot; data-video-play-service=&quot;kakao_tv&quot;&gt;&lt;iframe src=&quot;https://play-tv.kakao.com/embed/player/cliplink/393114614?service=kakao_tv&quot; width=&quot;854&quot; height=&quot;479&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;
&lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;음성인식은 앞서 설명한 바와 같이 입력받은 음성을 분석해 문장으로 변환하는 기술을 말합니다. 현재 카카오엔터프라이즈에서는 뉴톤(Newtone)이라는 이름으로 카카오맵, 현대자동차 등에 음성인식 서비스를 제공하고 있습니다. 음성인식에 대한 자세한 정보는 김훈님의 &lt;a href=&quot;https://brunch.co.kr/@kakao-it/105&quot;&gt;[카카오AI리포트]음성인식 방법과 카카오i의 음성형엔진&lt;/a&gt; 을 참고하시기 바랍니다.&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;음성합성&lt;/h3&gt;
&lt;figure data-ke-type=&quot;video&quot; data-ke-style=&quot;alignCenter&quot; data-video-host=&quot;kakaotv&quot; data-video-url=&quot;https://play-tv.kakao.com/channel/2743187/cliplink/393114531&quot; data-video-thumbnail=&quot;https://scrap.kakaocdn.net/dn/8XHl3/hyGMv4FM1U/4wA3NhufIoDZuH6oNT7ZN1/img.png?width=854&amp;amp;height=479&amp;amp;face=125_41_446_302,https://scrap.kakaocdn.net/dn/csRxcL/hyGK7EkayF/kAFoFPjyiOZaeJSKhBoR4k/img.jpg?width=640&amp;amp;height=360&amp;amp;face=0_0_640_360&quot; data-video-width=&quot;854&quot; data-video-height=&quot;479&quot; data-ke-mobilestyle=&quot;widthContent&quot; data-video-play-service=&quot;kakao_tv&quot;&gt;&lt;iframe src=&quot;https://play-tv.kakao.com/embed/player/cliplink/393114531?service=kakao_tv&quot; width=&quot;854&quot; height=&quot;479&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;
&lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;음성합성이란, 입력받은 문장으로부터 사람의 목소리를 생성하는 기술입니다. 수많은 음성 단위들을 연결하여 완성된 문장을 만드는 Unit selection 방식의 음성합성 모델이 뉴톤 톡(Newtone Talk)이라는 이름으로 카카오미니, 카카오내비, 카카오버스, 카카오지하철 등 다양한 서비스에 적용되어 있습니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;최근 DNN 방식의 음성합성 엔진인 딥 보이스(Deep Voice)가 카카오브레인과의 협업으로 개발되어 다양한 기기 속 뉴스 읽기 서비스에 활용되고 있습니다. 관련 정보는 &lt;a href=&quot;https://brunch.co.kr/@samantha89/126&quot;&gt;[후기] 딥보이스 제작 비하인드 스토리&lt;/a&gt; 에서 더 자세하게 확인할 수 있습니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;카카오엔터프라이즈의 음성인식과 음성합성 기술은 Open API를 통해 누구든지 서비스를 사용할 수 있으며, &lt;a href=&quot;https://developers.kakao.com/product/voice&quot;&gt;Kakao Developers&lt;/a&gt; 에서 확인해 볼 수 있습니다.&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;핵심어 검출&lt;/h3&gt;
&lt;figure data-ke-type=&quot;video&quot; data-ke-style=&quot;alignCenter&quot; data-video-host=&quot;kakaotv&quot; data-video-url=&quot;https://play-tv.kakao.com/channel/2743187/cliplink/394345067&quot; data-video-thumbnail=&quot;https://scrap.kakaocdn.net/dn/h3ifB/hyGMlN7qjJ/LwwV7oE17uZbUupMUDCjK1/img.png?width=1080&amp;amp;height=602&amp;amp;face=0_0_1080_602,https://scrap.kakaocdn.net/dn/EeQBL/hyGMwWo9Yz/8HprXY7euFKB0WGLzwWBn1/img.jpg?width=640&amp;amp;height=360&amp;amp;face=0_0_640_360&quot; data-video-width=&quot;854&quot; data-video-height=&quot;479&quot; data-ke-mobilestyle=&quot;widthContent&quot; data-video-play-service=&quot;kakao_tv&quot;&gt;&lt;iframe src=&quot;https://play-tv.kakao.com/embed/player/cliplink/394345067?service=kakao_tv&quot; width=&quot;854&quot; height=&quot;479&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;
&lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;핵심어 검출은 사용자가 kakao i 디바이스를 깨우기 위해 사용되는 기술입니다. &amp;lsquo;헤이카카오&amp;rsquo;나 &amp;lsquo;카카오미니&amp;rsquo; 등의 이름을 부르면 kakao i와 대화를 시작할 수 있습니다. 현재는 지정되어 있는 단어들만 인식이 가능하지만 사용자가 지정한 단어로 kakao i가 적용된 기기들을 깨우기 위한 연구가 진행되고 있습니다. 핵심어 검출에 대한 자세한 정보는&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;정대성님과 박종세님의&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt; &lt;/span&gt;&lt;a href=&quot;https://tech.kakaoenterprise.com/42?category=909203&quot;&gt;&lt;span&gt;&quot;헤이, 카카오!&quot;를 불러야 하는 이유&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt; 를 참고하기 바랍니다.&lt;/span&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;화자 인식&lt;/h3&gt;
&lt;figure data-ke-type=&quot;video&quot; data-ke-style=&quot;alignCenter&quot; data-video-host=&quot;kakaotv&quot; data-video-url=&quot;https://play-tv.kakao.com/channel/2743187/cliplink/394345197&quot; data-video-thumbnail=&quot;https://scrap.kakaocdn.net/dn/bvWozz/hyGMpprl0i/RrMjbY7AoankoKwu8CkMSK/img.png?width=854&amp;amp;height=480&amp;amp;face=328_140_593_373,https://scrap.kakaocdn.net/dn/KxlIj/hyGK1KuYaf/GCb2PGMpRN3KKUe2lRUD20/img.jpg?width=640&amp;amp;height=360&amp;amp;face=0_0_640_360&quot; data-video-width=&quot;854&quot; data-video-height=&quot;479&quot; data-ke-mobilestyle=&quot;widthContent&quot; data-video-play-service=&quot;kakao_tv&quot;&gt;&lt;iframe src=&quot;https://play-tv.kakao.com/embed/player/cliplink/394345197?service=kakao_tv&quot; width=&quot;854&quot; height=&quot;479&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;
&lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;화자 인식은 입력된 음성을 미리 등록된 DB와 비교하여 화자가 누구인지 식별하는 기술로, 카카오미니 역시 이를 통해 대화를 시작한 사람이 누구인지 알아낼 수 있습니다. 현재, 등록된 목소리와 일치하는 목소리로 카카오미니를 불렀을 때, 사용자에게 맞춤형 답변을 제공하는 &lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;보이스 프로필&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;이 베타서비스 중에 있습니다. 화자 인식 관련 자세한 내용은 &lt;/span&gt;&lt;a href=&quot;https://brunch.co.kr/@kakao-it/135&quot;&gt;&lt;span&gt;[카카오AI리포트]카카오미니는 목소리를 어떻게 인식할까&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt; 를 참고하기 바랍니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 data-ke-size=&quot;size26&quot;&gt;마치며&lt;/h2&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;지금까지 사람의 말소리 한 문장에 어떤 음성 정보들이 들어 있는지, 그리고 이를 AI가 이해할 수 있는 특징 벡터로 어떻게 만드는지 등에 대한 기본적인 내용을 설명했습니다. 카카오엔터프라이즈는 나아가 사용자에게 새롭고 더 편리한 경험을 선사하기 위해, 앞서 설명하지 않은 다양한 연구 결과를 축적 중이며 관련된 서비스를 제공할 계획입니다.&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;또한, 앞으로 연재될 블로그 글과 if kakao 행사를 통해 더 발전된 카카오엔터프라이즈의 음성처리 연구들을 여러분들에게 소개하겠습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style6&quot; /&gt;
&lt;div class=&quot;kep-recruit&quot;&gt;&lt;img class=&quot;img-recruit&quot; src=&quot;https://mk.kakaocdn.net/dn/kep-web/kep-blog/img_recruit.png&quot; /&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;새로운 길에 도전하는 최고의 Krew들과 함께 해요!&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://kakaoenterprise.recruiter.co.kr/app/jobnotice/view?systemKindCode=MRS2&amp;amp;jobnoticeSn=16941&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[AI기술] 음성처리 기술 개발자 모집&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;original.jpg&quot; data-origin-width=&quot;453&quot; data-origin-height=&quot;453&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/m4Njs/btqFFUfxvlE/NcVnmj6fxTkAsdPVl47Dtk/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/m4Njs/btqFFUfxvlE/NcVnmj6fxTkAsdPVl47Dtk/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fm4Njs%2FbtqFFUfxvlE%2FNcVnmj6fxTkAsdPVl47Dtk%2Fimg.jpg' data-filename=&quot;original.jpg&quot; data-origin-width=&quot;453&quot; data-origin-height=&quot;453&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;장원(taylor)&lt;/p&gt;
&lt;p class=&quot;desc&quot;&gt;보다 선명하고, 보다 인간적인 감정을 녹여낼 수 있는 미래 음성합성 기술을 연구하는 중입니다.&lt;br /&gt;일상의 사소한 불편을 해소하기 위한 kakao i의 목표에 기여하고 싶습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;krew-image.png&quot; data-origin-width=&quot;200&quot; data-origin-height=&quot;200&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bKDBn3/btqFDxej53J/8oswTMF8gL8hMKD2xBqxvk/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/bKDBn3/btqFDxej53J/8oswTMF8gL8hMKD2xBqxvk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbKDBn3%2FbtqFDxej53J%2F8oswTMF8gL8hMKD2xBqxvk%2Fimg.png' data-filename=&quot;krew-image.png&quot; data-origin-width=&quot;200&quot; data-origin-height=&quot;200&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;박진우(woody)&lt;/p&gt;
&lt;p class=&quot;desc&quot;&gt;만화를 보며 로봇과 대화하는 세상을 꿈꿨던 개발자입니다.&lt;br /&gt;꿈꾸던 미래를 위해 다양한 플랫폼에 카카오엔터프라이즈의 음성처리 기술을 연결 시키는 일을 하고 있습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
<category>Tech Log</category>
<category>Kakao I</category>
<category>Mel scale</category>
<category>MFCC</category>
<category>음성</category>
<category>음성인식</category>
<category>음성합성</category>
<category>카카오미니</category>
<category>특징벡터</category>
<category>핵심어검출</category>
<category>화자인식</category>
<author>준팔이(jun.8)</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/66</guid>
<comments>https://tech.kakaoenterprise.com/66#entry66comment</comments>
<pubDate>Mon, 10 Aug 2020 13:27:39 +0900</pubDate>
</item>
<item>
<title>기술 문서 작성 5단계</title>
<link>https://tech.kakaoenterprise.com/65</link>
<description>&lt;h2&gt;&lt;span&gt;시작하며&lt;/span&gt;&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;안녕하세요. 카카오엔터프라이즈에서 테크니컬 라이터 업무를 진행하고 있는 테크니컬커뮤니케이션 셀의 Crystal(김유리)과 Sandy(차신영)입니다. :)&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;이전 포스팅(&lt;/span&gt;&lt;a href=&quot;https://tech.kakaoenterprise.com/59&quot;&gt;&lt;span&gt;Technical Writer에서 Technical Communicator로&amp;hellip;&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;)에서는 Technical Communication에 대한 정의와 역사 그리고 어떤 업무를 하는지에 대해서 알아보았습니다. 지난번에도 잠깐 언급했듯이 해외에서는 테크니컬 라이팅의 학위 프로그램도 존재하며, 학계에서는 관련 프로세스가 확립 되어있는데요. 이를 바탕으로, 이번 포스트의 주제는 기술적인 정보를 특정 독자들에게 정확하고 명확하게 전달하기 위해 어떤 프로세스로 진행해야 하는지에 대해 간단히 말씀드리려고 합니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt; Kieran Morgan의 &lt;/span&gt;&lt;a href=&quot;https://technicalwritingprocess.com/&quot;&gt;&lt;span&gt;Technical Writing Process&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: #000000;&quot;&gt;라는 책과 소프트웨어 사용자 문서 프로세스(Software user documentation process, ISO/IEC 15910) 표준을 기반으로 한, 카카오엔터프라이즈의 기술 문서 작성 과정을 지금부터 소개해드리겠습니다.&lt;span style=&quot;color: #ee2323;&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;과연 여러분이 예상하는 기술 문서 생성 과정과 같을지, 한번 생각하고 읽으시면 더 흥미롭게 읽으실 수 있을 것 같습니다. :)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;테크니컬 라이팅 프로세스&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;다음은 Technical Writing Process 책에서 발췌한 테크니컬 라이팅 프로세스입니다.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;기술블로그표2.jpg&quot; data-origin-width=&quot;1232&quot; data-origin-height=&quot;844&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/dAvrQg/btqFvu97nj4/0xAc36BkdxGx65UrG2xtg1/img.jpg' data-lightbox='lightbox' data-alt='[그림 1] 테크니컬 라이팅 프로세스'&gt;&lt;img src='https://blog.kakaocdn.net/dn/dAvrQg/btqFvu97nj4/0xAc36BkdxGx65UrG2xtg1/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdAvrQg%2FbtqFvu97nj4%2F0xAc36BkdxGx65UrG2xtg1%2Fimg.jpg' data-filename=&quot;기술블로그표2.jpg&quot; data-origin-width=&quot;1232&quot; data-origin-height=&quot;844&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 1] 테크니컬 라이팅 프로세스&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;저희 테크니컬커뮤니케이션 셀에서도 위의 테크니컬 라이팅 5단계를 바탕으로 카카오엔터프라이즈 환경에 맞게 기술 문서를 생성하고 있는데요. 각 단계별 상세 내용을 살펴보도록 하겠습니다.&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span&gt;기획(Plan)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;01.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/dxNrVd/btqFWAUPDtH/QhkrPhYZwLY8Fkxo9j6lFk/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/dxNrVd/btqFWAUPDtH/QhkrPhYZwLY8Fkxo9j6lFk/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdxNrVd%2FbtqFWAUPDtH%2FQhkrPhYZwLY8Fkxo9j6lFk%2Fimg.jpg' data-filename=&quot;01.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;첫 번째 단계는 문서 기획 단계로, 프로젝트 Kick-off 미팅에서 논의되는 것이 가장 이상적입니다. 테크니컬 라이터는 보통 프로젝트 매니저와 다음의 항목들을 정의합니다.&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse; width: 100%;&quot; border=&quot;1&quot; data-ke-style=&quot;style12&quot;&gt;&lt;caption&gt;[표 1] 기획 단계에서 정의되는 항목&lt;/caption&gt;
&lt;tbody&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 18.9535%; height: 19px; text-align: center;&quot;&gt;&lt;b&gt;구분&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 81.0465%; height: 19px; text-align: center;&quot;&gt;&lt;b&gt;설명&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 18.9535%; height: 19px;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;b&gt;문서 작성 범위&lt;/b&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style=&quot;width: 81.0465%; height: 19px;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;개발 Phase에 따라 산출되는 문서의 종류나 콘텐츠가 다른 경우 등을 고려한 문서 작성 범위 정의&lt;br /&gt;&amp;nbsp; - 다국어 버전 필요 시, 번역 언어 정의&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 18.9535%; height: 19px;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;b&gt;문서 이해관계자&lt;/b&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td style=&quot;width: 81.0465%; height: 19px;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문서 산출과 관련된 모든 이해관계자 정의&lt;br /&gt;&amp;nbsp; - 초안 작성자, 테크니컬 라이터, 문서 검토자, 피어 리뷰(Peer Review) 진행자, 문서 최종 승인자, 문서 배포자 등 정의&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 18.9535%; height: 19px;&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #000000;&quot;&gt;프로세스&lt;/span&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 81.0465%; height: 19px;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;각 프로젝트 특성에 따른 프로세스 정의&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp; - 예를 들어, 이미 문서 초안이 존재하는 경우, 초안 작성 단계 생략 후 검수 단계부터 진행&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 18.9535%; height: 19px;&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문서 작성 도구&lt;/span&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 81.0465%; height: 19px;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문서 초안 작성 도구 선택&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp; - 사내 부서별로 사용하는 문서 작성 도구(Google Docs, Wiki, Notion, Markdown Editor 등)가 다를 수 있기 때문에 문서 작성 도구 사전 협의&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 18.9535%; height: 19px;&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #000000;&quot;&gt;파일 형식&lt;/span&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 81.0465%; height: 19px;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문서 파일 형식 정의&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp; - 문서 작성 도구에 따라 Export할 수 있는 파일 형식이 다르기 때문에, 파일 산출 형식(PDF, HTML 5 등)을 정의&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&amp;nbsp; - Web으로 제공 시에는 보안 사항 등도 함께 정의&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 18.9535%; height: 19px;&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문서 일정&lt;/span&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 81.0465%; height: 19px;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문서 생성 관련 템플릿 전달, 초안 완료, 1차 검수본 전달, 2차 검수본 전달, 피어 리뷰 완료, 최종 문서 배포 등의 일정 수립&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span&gt;구조화(Structure)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;02.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/kAeg0/btqFUBG9nNi/kOXeFkDjeAiKlADjl9g910/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/kAeg0/btqFUBG9nNi/kOXeFkDjeAiKlADjl9g910/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkAeg0%2FbtqFUBG9nNi%2FkOXeFkDjeAiKlADjl9g910%2Fimg.jpg' data-filename=&quot;02.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;두 번째 단계는 목차 구조화 단계입니다. 기획 단계에서 초안 작성자와 템플릿 등이 지정된 후, 본격적으로 초안 작성자와 테크니컬 라이터는 회의를 통해 문서의 목차(Table of Contents)를 함께 구성합니다. 목차만 잘 구성해도 문서 작업의 절반이 끝났다고 자신 있게 말할 수 있을 정도로, 목차 구성은 테크니컬 라이팅의 핵심 작업이라 할 수 있습니다.&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문서 구조화는 레퍼런스 문서를 분석하고, 가독성, 독자의 편의성 등을 고려해야 하는데 이 과정이 익숙하지 않은 개발자들의 경우 목차 작성에 많은 어려움을 호소하는 경우가 있습니다. 따라서 목차 작성은 본격적인 문서 작성 전, 테크니컬 라이터와 함께 진행하시면 더욱 좋을 것 같습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;카카오엔터프라이즈 내부적으로는 문서별 템플릿과 스타일 가이드, 목차 구성 가이드를 활용하고 있는데요. 아래와 같은 페이지를 통해 개발자들과 테크니컬 라이터들이 효과적인 목차 구성을 위해 협업하고 있습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;blob&quot; data-origin-width=&quot;1217&quot; data-origin-height=&quot;1360&quot; width=&quot;820&quot; height=&quot;NaN&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bajaJ3/btqFD6acfbr/26kuJK2sKp1RcKAy068nAK/img.png' data-lightbox='lightbox' data-alt='[그림 2] 테크니컬커뮤니케이션 셀 내부 페이지'&gt;&lt;img src='https://blog.kakaocdn.net/dn/bajaJ3/btqFD6acfbr/26kuJK2sKp1RcKAy068nAK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbajaJ3%2FbtqFD6acfbr%2F26kuJK2sKp1RcKAy068nAK%2Fimg.png' data-filename=&quot;blob&quot; data-origin-width=&quot;1217&quot; data-origin-height=&quot;1360&quot; width=&quot;820&quot; height=&quot;NaN&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 2] 테크니컬커뮤니케이션 셀 내부 페이지&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span&gt;문서 작성(Write)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;03.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/Z5GdM/btqFXhUMlyS/CJ4nxqJM6xbIQ0AmgyYqOk/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/Z5GdM/btqFXhUMlyS/CJ4nxqJM6xbIQ0AmgyYqOk/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZ5GdM%2FbtqFXhUMlyS%2FCJ4nxqJM6xbIQ0AmgyYqOk%2Fimg.jpg' data-filename=&quot;03.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;세 번째 단계는 초안 작성자가 초안을 작성하고, 해당 초안을 테크니컬 라이터가 리라이팅(Rewriting)하는 단계입니다. 국내의 경우 외국에 비해 문서화의 중요성에 대한 인지도가 상대적으로 떨어지기 때문에, 문서 작업은 개발과 별개인 부차적인 업무로 생각되는 경우가 많습니다. 각 개발 세부 단계마다 문서를 작성하지 않고, 개발을 모두 완료한 후에 문서 작성을 시작하면, 이슈 대응, 긴급 프로젝트 투입 등의 이유로 시간에 쫓겨 결국 반쪽 짜리 문서가 만들어지기 쉽습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;위와 같은 문제는 문서 작성에 얼마나 많은 시간이 소요되는지 파악하지 못해 생기게 되는데요. &lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;문서의 내용이나 난이도에 따라 다르겠지만 ISO/IEC 표준에 따르면 문서 한 페이지의 초안을 작성하는 데 1시간이 소요된다고 합니다. 예를 들어 30장의 문서를 작성하기 위해서는 30시간이 필요한 것입니다. 다시 말해 하루 8시간씩 4일 정도를 꼬박 문서 작업에 몰두해야 한다는 계산이 나옵니다. 하지만 이렇게 하루 종일 문서 작업에만 집중하는 것은 현실적으로 불가능하며, 다른 업무를 동시에 처리하다 보면 결국 하루에 3~4시간도 문서 작업에 할당하기 힘들어집니다. 이런 현실을 고려하면 보통 예정된 문서 초안 일정이 몇 주씩 늦춰지게 되며, 이렇게 초안이 늦춰지면 다음 단계인 &quot;리뷰(Review)&quot; 단계에 할애할 시간이 단축되고, 이는 곧 문서 품질 저하를 의미합니다. 따라서 정확한 일자에 초안이 완료되는 것이 매우 중요하다고 할 수 있습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse; width: 100%;&quot; border=&quot;1&quot; data-ke-style=&quot;style12&quot;&gt;&lt;caption&gt;[표 2]&amp;nbsp; 문서 작성 소요 시간 (ISO/IEC 15910-2002) (출처: &lt;a style=&quot;color: #666666;&quot; href=&quot;https://insights.sigasi.com/tech/how-much-time-spent-writing-documentation-versus-developing-rtl-code&quot;&gt;Sigasi&lt;/a&gt;)&lt;/caption&gt;
&lt;tbody&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 29.6124%; height: 19px;&quot;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td style=&quot;width: 35.1937%; height: 19px;&quot;&gt;&lt;b&gt;ISO/IEC 15910-2002&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1938%; height: 19px;&quot;&gt;&lt;b&gt;READ ME 1ST(Sun)&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 29.6124%; height: 19px;&quot;&gt;&lt;b&gt;Writing&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1937%; height: 19px;&quot;&gt;1 hour/page&lt;/td&gt;
&lt;td style=&quot;width: 35.1938%; height: 19px;&quot;&gt;3-5 &lt;span style=&quot;color: #333333;&quot;&gt;hours/page&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 29.6124%; height: 19px;&quot;&gt;&lt;b&gt;Reviewing&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1937%; height: 19px;&quot;&gt;0.5 hours/page&lt;/td&gt;
&lt;td style=&quot;width: 35.1938%; height: 19px;&quot;&gt;1-3 &lt;span style=&quot;color: #333333;&quot;&gt;hours/page&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 29.6124%; height: 19px;&quot;&gt;&lt;b&gt;Editing&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1937%; height: 19px;&quot;&gt;~2.5 hours/page&lt;/td&gt;
&lt;td style=&quot;width: 35.1938%; height: 19px;&quot;&gt;0.2 &lt;span style=&quot;color: #333333;&quot;&gt;hours/page&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 29.6124%; height: 19px;&quot;&gt;&lt;b&gt;Indexing&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1937%; height: 19px;&quot;&gt;-&lt;/td&gt;
&lt;td style=&quot;width: 35.1938%; height: 19px;&quot;&gt;5 &lt;span style=&quot;color: #333333;&quot;&gt;hours/page&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 29.6124%; height: 19px;&quot;&gt;&lt;b&gt;Proofreading&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1937%; height: 19px;&quot;&gt;0.25 &lt;span style=&quot;color: #333333;&quot;&gt;hours/page&lt;/span&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1938%; height: 19px; text-align: left;&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 29.6124%; height: 19px;&quot;&gt;&lt;b&gt;Production&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1937%; height: 19px;&quot;&gt;8-10 days&lt;/td&gt;
&lt;td style=&quot;width: 35.1938%; height: 19px;&quot;&gt;5% of a project&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 29.6124%; height: 19px;&quot;&gt;&lt;b&gt;Project management&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1937%; height: 19px;&quot;&gt;~100 &lt;span style=&quot;color: #333333;&quot;&gt;hours/project&lt;/span&gt;&lt;/td&gt;
&lt;td style=&quot;width: 35.1938%; height: 19px;&quot;&gt;10-15% of a project&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p style=&quot;text-align: center;&quot; data-ke-size=&quot;size14&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;개발자의 초안 작성이 완료되면, 테크니컬 라이터의 리라이팅 작업이 시작됩니다. 개발자들은 보통 &quot;이 내용은 개발자라면 모두 알고 있을 거야&quot;라고 가정하고 반드시 필요한 정보를 생략하고 본론으로 바로 넘어가는 경향이 있는데요. 기술 문서는 회사 외부의 초급 개발자들도 쉽게 따라 할 수 있도록 최대한 상세하게 작성해야 합니다. 테크니컬 라이터는 초안 문서에 누락된 설명을 보완 및 수정하고, 테크니컬 라이팅 4대 원칙인 명확성, 간결성, 정확성, 일관성에 입각하여 초안을 리라이팅 한 후, 가독성과 사용성 측면에서 문서를 편집합니다. 리라이팅의 경우, 기술적인 내용을 정확히 알아야 초안을 수정할 수 있기 때문에 본격적인 수정 및 편집 작업 전 초안 작성자에게 관련 교육을 요청하고, Q&amp;amp;A를 주고받는 작업이 진행됩니다. ISO 표준에 따르면, 한 페이지당 수정 및 편집 단계에 각각 0.5시간, 2.5시간까지 소요되므로 총 3시간의 작업시간이 필요합니다.&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span&gt;리뷰(Review)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;04.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/ZaG19/btqFT7M24on/E2w8bejhMv3X3p0M96iEAK/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/ZaG19/btqFT7M24on/E2w8bejhMv3X3p0M96iEAK/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FZaG19%2FbtqFT7M24on%2FE2w8bejhMv3X3p0M96iEAK%2Fimg.jpg' data-filename=&quot;04.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;세 번째 단계는 리뷰(Review) 단계로 작성된 문서를 기술적인 측면과 스타일적인 측면에서 확인하는 단계입니다. 기술적인 리뷰에서는 문서의 기술적인 내용에 오류가 없는지에 초점을 맞춰 진행되며, 보통 초안 작성자와 초안 작성자가 속한 팀 내의 다른 개발자가 진행합니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;기술적으로 수정 또는 보완되어야 하는 내용이 있을 경우, 다시 &quot;작성(Write)&quot; 단계로 되돌아가 문서 작업을 진행합니다. 반면 스타일적인 리뷰는 동료 테크니컬 라이터와 문서 내 용어/표현의 통일성, 스타일 가이드/용어집의 준수 여부, 맞춤법 등을 리뷰하는 과정으로 피어 리뷰(Peer Review)라고도 합니다. ISO 표준에 따르면, 페이지당 내용 리뷰에는 30분, 단순 교정 작업에는 약 15분이 소요됩니다.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/u9CM1/btqFGyjFTth/buTLM9lizV6zsmMtAA3mDK/img.png' data-lightbox='lightbox' data-alt='[그림 3] 피어 리뷰 과정에서 의견 교환'&gt;&lt;img src='https://blog.kakaocdn.net/dn/u9CM1/btqFGyjFTth/buTLM9lizV6zsmMtAA3mDK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fu9CM1%2FbtqFGyjFTth%2FbuTLM9lizV6zsmMtAA3mDK%2Fimg.png' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 3] 피어 리뷰 과정에서 의견 교환&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 data-ke-size=&quot;size23&quot;&gt;&lt;span&gt;배포(Publish)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;05.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bBM2Bh/btqFVhBslNJ/L3VaH7KRbWRYyyiqWciDkk/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/bBM2Bh/btqFVhBslNJ/L3VaH7KRbWRYyyiqWciDkk/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbBM2Bh%2FbtqFVhBslNJ%2FL3VaH7KRbWRYyyiqWciDkk%2Fimg.jpg' data-filename=&quot;05.jpg&quot; data-origin-width=&quot;1800&quot; data-origin-height=&quot;640&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;마지막 단계는 최종 문서를 고객에게 전달하기 위한 배포 단계입니다. 문서가 종이 책이나 PDF 포맷으로 배포되었던 과거와는 달리, 최근에는 웹 상에 문서를 배포하는 것이 추세입니다. 웹 배포의 장점은 누구나 쉽게 URL을 통해 문서에 접근할 수 있다는 점이지만, 특정 고객사에게만 배포되어야 하는 문서나 기밀문서의 경우에는 PDF 포맷을 사용하거나 Google Docs 등의 권한 관리 기능을 사용하여 특정 사용자에게만 권한을 부여하는 작업을 하기도 합니다. 테크니컬커뮤니케이션 셀에서는 문서 배포 이후의 문서 데이터베이스, 버전 관리도 진행합니다. 시간이 흘러 누군가가 &quot;3년 전에 A 고객사한테 전달했던 그 문서가 필요해요&quot;라는 요구에 당황하지 않고 대응하기 위해서입니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;다음은 위 5단계를 거쳐 배포가 완료된 기술 문서의 예시인데요. 최근 트렌드에 맞게 웹에 배포한 모습입니다. 아래 이미지의 문서 정보에서 볼 수 있듯이 각 문서별로 버전을 명시해 이후 문서 관리 목록에서 누락되지 않도록 관리하고 있습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;배포.png&quot; data-origin-width=&quot;1736&quot; data-origin-height=&quot;1318&quot; width=&quot;821&quot; height=&quot;NaN&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bapkAH/btqFElrueST/OHBcMZir2kzl47KkAuEXGk/img.png' data-lightbox='lightbox' data-alt='[그림 4] 배포된 기술 문서 표지'&gt;&lt;img src='https://blog.kakaocdn.net/dn/bapkAH/btqFElrueST/OHBcMZir2kzl47KkAuEXGk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbapkAH%2FbtqFElrueST%2FOHBcMZir2kzl47KkAuEXGk%2Fimg.png' data-filename=&quot;배포.png&quot; data-origin-width=&quot;1736&quot; data-origin-height=&quot;1318&quot; width=&quot;821&quot; height=&quot;NaN&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 4] 배포된 기술 문서 표지&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 style=&quot;text-align: left;&quot;&gt;마무리하며&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;지금까지 테크니컬 라이팅이 진행되는 단계별 프로세스를 살펴보았는데요. 위의 프로세스에 따라 작업이 진행되면 이상적이지만, 현실적으로 이 프로세스가 제대로 지켜지지 않는 경우가 많습니다. 예를 들어, 테크니컬 라이터들에게 협업 요청 없이 초안을 바로 작성하거나, 초안 문서 리라이팅이 70% 정도 끝난 시점에서 개발에 엄청난 변경점이 생겨 초안부터 다시 작성해야 한다거나, 국문 버전만 요청했던 고객이 갑자기 영문이 필요하다고 요청하기도 하며, 프로젝트 일정 변경 사항이 제대로 전달되지 않는 등 여러 크고 작은 문제에 직면합니다.&lt;/span&gt;&lt;span style=&quot;color: #000000;&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;창작 글쓰기뿐만 아니라 기술적 글쓰기에도 상당한 노력과 인내가 필요합니다. 앞서, 초안글 한 페이지 작성하는데 보통 한 시간이 걸린다고 말씀드렸는데요. 그렇다면 총 작업 시간은 얼마나 걸릴까요? STC(The Society for Technical Communication)의 통계에 따르면 한 페이지당 총 작업시간은 약 8시간이 소요된다고 합니다. 따라서 문서 한 페이지를 제대로 작성하려면 이렇게 엄청난 시간과 노력이 필요하다는 점을 프로젝트 참여자 전원이 인지하고, 테크니컬 라이팅 프로세스의 존재를 인지하며, 최대한 프로세스를 준수하려고 노력할 때 문서화 작업은 더욱 효율적으로 진행되며, 문서의 품질은 향상될 것입니다.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;저희 테크니컬커뮤니케이션 셀에서는 앞으로도 테크니컬 라이팅 프로세스에 대해 홍보하고, 테크니컬 라이팅에 관련한 유용한 주제들을 기술 블로그에 기고할 예정입니다. 앞으로도 많은 관심을 부탁드리며, 글을 마치겠습니다. 감사합니다. :)&lt;/span&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;스크린샷 2020-08-06 오전 11.03.41.png&quot; data-origin-width=&quot;898&quot; data-origin-height=&quot;1198&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/tJHHe/btqGkUSqV2M/bQlSKHlae8qmxhKiS9lR1k/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/tJHHe/btqGkUSqV2M/bQlSKHlae8qmxhKiS9lR1k/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtJHHe%2FbtqGkUSqV2M%2FbQlSKHlae8qmxhKiS9lR1k%2Fimg.png' data-filename=&quot;스크린샷 2020-08-06 오전 11.03.41.png&quot; data-origin-width=&quot;898&quot; data-origin-height=&quot;1198&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;김유리(Crystal)&lt;/p&gt;
&lt;p class=&quot;desc&quot;&gt;사용자의 입장에서 생각하고, 개발자와 원활한 소통을 할 수 있는 Communication Skill을 가진 Technical Communicator입니다. 카카오엔터프라이즈의 값진 기술들을 정확하고 명확하게 전달하고, 신뢰를 쌓을 수 있는 문서를 만들고자 합니다.&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;krew-image.png&quot; data-origin-width=&quot;200&quot; data-origin-height=&quot;200&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/corYaV/btqFAN1UOuF/JsBvH1nFIZcRHJ00il5MMk/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/corYaV/btqFAN1UOuF/JsBvH1nFIZcRHJ00il5MMk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcorYaV%2FbtqFAN1UOuF%2FJsBvH1nFIZcRHJ00il5MMk%2Fimg.png' data-filename=&quot;krew-image.png&quot; data-origin-width=&quot;200&quot; data-origin-height=&quot;200&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;차신영(Sandy)&lt;/p&gt;
&lt;p class=&quot;desc&quot;&gt;산더미처럼 쌓여진 문서 정리, 새로운 문서화 도구 테스트, 그리고 구글링이 취미인 Technical Communicator입니다.&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-recruit&quot;&gt;&lt;img class=&quot;img-recruit&quot; src=&quot;https://mk.kakaocdn.net/dn/kep-web/kep-blog/img_recruit.png&quot; /&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;새로운 길에 도전하는 최고의 Krew들과 함께 해요!&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://kakaoenterprise.recruiter.co.kr/app/jobnotice/view?systemKindCode=MRS2&amp;amp;jobnoticeSn=33534&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Technical Writer 영입&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<category>Krew Talk</category>
<category>Technical Communication</category>
<category>technical writing</category>
<category>Tw</category>
<category>기술 문서 작성 5단계</category>
<category>기술 문서 작성 프로세스</category>
<category>카카오엔터프라이즈</category>
<category>카카오엔터프라이즈채용</category>
<category>테크니컬 라이팅</category>
<category>테크니컬커뮤니케이션셀</category>
<author>celina.7</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/65</guid>
<comments>https://tech.kakaoenterprise.com/65#entry65comment</comments>
<pubDate>Wed, 29 Jul 2020 14:06:25 +0900</pubDate>
</item>
<item>
<title>정답 유형을 분류하는 딥러닝 기술</title>
<link>https://tech.kakaoenterprise.com/64</link>
<description>&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;시작하며&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;현대인은 자신이 원하는 정보를 찾는 데 점차 많은 어려움을 느끼고 있습니다. 언제 어디서나 경제적인 부담없이 편리하게 정보를 습득할 수 있는 인터넷이 가진 장점과는 별개로, 유용한 정보에 접근하는 데에는 물리적인 한계가 존재하기 때문입니다. 모르거나 모를 수밖에 없는 정보량이 압도적으로 많이 생산되고 있어 특정 상황과 조건에 따른 답을 파악하기가 쉽지 않죠. 이런 이유로 부정확하거나 잘못된 정보를 습득할 가능성도 이전보다 더 높아짐은 물론, 검색 정보를 이해하고 활용하는 수준이 낮아서 발생하는 새로운 형태의 불평등도 야기되고 있습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;카카오엔터프라이즈 AI Lab(이하 AI Lab)이 자사 인공지능 기술을 집약한 플랫폼인 '카카오 i'의 대화 엔진 &lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_1&quot; href=&quot;#footnote_64_1&quot; onmouseover=&quot;tistoryFootnote.show(this,64,1)&quot; onmouseout=&quot;tistoryFootnote.hide(64,1)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;1&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;을 고도화하는 이유는 사용자에게 도움이 될만한 정보를 효율적으로 찾아주는 검색 시스템의 중요성을 인지하고 있기 때문입니다. 그 중에서도 음성, 키보드와 같은 다양한 인터페이스를 통해 입력된 사용자 질의(query)에 대한 답을 포함하는 후보 문서에서 정답 부분을 추출하는 기술인 &amp;lsquo;질의 응답&amp;rsquo;에 대한 연구([그림 1])를 활발하게 진행하고 있습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/MkGph/btqFIGVi5Un/4iXEkNIvjXhtVKobYxb5rk/img.png' data-lightbox='lightbox' data-alt='[그림 1] 질의 응답 시스템의 동작 과정'&gt;&lt;img src='https://blog.kakaocdn.net/dn/MkGph/btqFIGVi5Un/4iXEkNIvjXhtVKobYxb5rk/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMkGph%2FbtqFIGVi5Un%2F4iXEkNIvjXhtVKobYxb5rk%2Fimg.png' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 1] 질의 응답 시스템의 동작 과정&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;이번 글에서는 질의 응답 시스템을 구성하는 요소 중 하나인 딥러닝 기반 정답 유형(서술형, 단답형) 분류 모델을 소개해보고자 합니다. AI Lab AI기술팀 자연어처리파트의 조승우 연구원을 만나 자세한 이야기를 들어봤습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;span style=&quot;color: #006dd7;&quot;&gt;※이번 글은 조승우 연구원과 최동현 연구원이 2019년 7월부터 2020년 2월까지 진행한 연구를 바탕으로 내용을 구성했습니다.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;질의 응답 시스템이란&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;카카오 i 대화 엔진은 사용자 질의 분석을 통해 호출 의도에 따른 적합한 시스템을 가동합니다. 이 내용은 &amp;lsquo;&lt;a href=&quot;https://tech.kakaoenterprise.com/43&quot;&gt;카카오미니의 명령어 분류 방법&lt;/a&gt;&amp;rsquo;이라는 글에 서술된 대화 엔진의 동작 방법에서 좀 더 자세히 살펴볼 수 있습니다. 그 중에서도 [표 1]에서처럼 인텐트 분류 단계를 거친 사용자 발화가 답변을 요구할 때 질의 응답 시스템이 활성화된다고 보시면 됩니다.&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse; width: 100%;&quot; border=&quot;1&quot; data-ke-style=&quot;style12&quot;&gt;&lt;caption&gt;[표 1] 답변을 요구하는 사용자 질의 예시&lt;/caption&gt;
&lt;tbody&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 50%; text-align: center; height: 19px;&quot;&gt;&lt;b&gt;질의&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 50%; height: 19px; text-align: center;&quot;&gt;&lt;b&gt;답변&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;토사구팽이 뭐야?&lt;/td&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;필요할 때 이용하다가 필요가 없어지면 버리는 일을 비유한 사자성어&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;소방서 전화번호가 뭐야?&lt;/td&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;119&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;아시아나 온라인 체크인은 언제부터 가능해?&lt;/td&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;출발 48시간 전부터&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;이효리가 속한 그룹 이름이 뭐야?&lt;/td&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;핑클&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;올림픽 공원은 어디에 있어?&lt;/td&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;서울 송파구 올림픽로 424&lt;/td&gt;
&lt;/tr&gt;
&lt;tr style=&quot;height: 19px;&quot;&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;교보문고 강남 어디에 있어?&lt;/td&gt;
&lt;td style=&quot;width: 50%; height: 19px;&quot;&gt;서울특별시 서초구 강남대로 465&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 50%;&quot;&gt;김태희 누구랑 결혼했어?&lt;/td&gt;
&lt;td style=&quot;width: 50%;&quot;&gt;비&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;질의 응답 시스템의 작동 과정은 다음과 같습니다. 첫 번째, 입력 문장을 분석해 검색에 유용한 쿼리를 생성합니다. 두 번째, 추출된 검색 쿼리를 활용해 찾은 모든 문서를 기계 독해에 적합한 형태로 잘게 쪼갭니다. 세 번째, 잘게 쪼갠 텍스트에서 후보 정답을 추출합니다. 네 번째, 후보 정답 중 질문에 가장 적합한 정답을 제공합니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;마지막 네 번째 단계에서 질의 응답 시스템은 질문과 가장 연관성이 높은 N개의 문서를 분석해 얻은 1) 서로 다른 N개의 정답을 각각 제시하거나, 또는 2) 여러 후보군에서 가장 적합한 단일 정답을 제시할 수 있습니다. 스마트 스피커와 같은 음성 인터페이스나 스마트폰과 같은 소형 디스플레이에서는 텍스트를 쪼갠 수만큼 늘어난 추출된 모든 정답을 사용자에게 그대로 제공하는 방식은 사용자에게 큰 불편함을 초래할 수 있습니다. 이런 이유로 하나의 정답을 제공하는 두 번째 방식이 보편적으로 활용되고 있습니다.&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;문제는 수많은 후보군 중 하나의 최종 정답을 제공하는 질의 응답 시스템에서는 하나의 알고리즘으로 서로 다른 정답 유형을 처리하기가 쉽지 않다는 데 있습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse; width: 100%;&quot; border=&quot;1&quot; data-ke-style=&quot;style12&quot;&gt;&lt;caption&gt;[표 2] 단답형 정답과 서술형 정답을 요구하는 질의 예시&lt;/caption&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 15%; text-align: center;&quot;&gt;&lt;b&gt;질의&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 20%; text-align: center;&quot;&gt;&lt;b&gt;마우스 발명자는 누구?&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 65%; text-align: center;&quot;&gt;&lt;b&gt;컴퓨터가 뭐야?&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;후보 정답 1&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;더글러스 엔젤바트&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%;&quot;&gt;미리 정해진 방법에 따라 입력된 자료를 처리함으로써 문제를 해결하는 다양한 형태의 전자공학적 자동장치&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;후보 정답 2&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;더글러스 엥겔바트&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%;&quot;&gt;반도체 집적 회로를 이용해 주어진 명령을 자동으로 맡아 실행하는 정보 처리기&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;후보 정답 3&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;더글라스 엥겔바트&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%;&quot;&gt;프로그램을 이용해 정보를 처리하는 장치&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;후보 정답 4&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;더글라스 엥겔바트&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%;&quot;&gt;전자 회로를 이용한 고속 자동 계산기&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;후보 정답 5&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%; text-align: center;&quot;&gt;더글러스 엥겔바트&lt;/td&gt;
&lt;td style=&quot;width: 33.333333333333336%;&quot;&gt;프로그램에 따라 작업이나 계산을 수행하는 기계&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;[표 2]에서 보듯이, &amp;ldquo;마우스 발명자는 누구&amp;rdquo;라는 질의에 따라 각 문서에서 추출한 후보군은 대부분 비슷한 문형&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_2&quot; href=&quot;#footnote_64_2&quot; onmouseover=&quot;tistoryFootnote.show(this,64,2)&quot; onmouseout=&quot;tistoryFootnote.hide(64,2)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;2&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;을 지니며 그 표현 범위 또한 다소 한정돼 있습니다. 그래서 그 후보를 압축하는 데 도움이 될만한 정답 사이 포함 관계나 날짜, 요일과 같은 규칙성에 따른 투표를 통해 최종 정답을 가려낼 수 있죠. 이를 단답형 정답이라고 부릅니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;반면, &amp;ldquo;컴퓨터가 뭐야&amp;rdquo;라는 질의에 따라 각 문서에서 추출한 후보군은 다양한 문형을 지니며 그 표현 범위가 상당히 넓습니다. 후보 답변 사이 규칙성을 발견하기 어려워 앞서 설명한 투표 알고리즘을 사용하기가 어렵습니다. 그래서 각 정답 후보에서 추출한 중심어와 수식어에 따른 &lt;a href=&quot;https://mk-v1.kakaocdn.net/dn/if-kakao/conf2019/conf_video_2019/2_104_03_m1.mp4&quot;&gt;새로운 투표 알고리즘&lt;/a&gt;이 필요합니다. 이를 서술형 정답이라고 부릅니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;이처럼 질의 응답 시스템에서는 정답의 유형에 따른 적절한 알고리즘이 동작해야 한다는 점에서 정답 유형 분류는 매우 중요하다고 할 수 있겠습니다.&lt;/p&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;정답 유형 분류가 어려운 이유&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;앞서 설명한 정답 유형 인식은 '단답형'과 '서술형'이라는 이진 분류 문제라고 볼 수 있습니다. 얼핏 봐서는 질문의 길이가 짧고 간단해 답변의 유형을 둘 중 하나로 분류하기가 매우 쉽다고 느껴질 수도 있습니다. 하지만 실제로는 질의의 형태만 봐서는 정답 유형을 구분하기가 거의 불가능합니다. 같은 문형을 가진 질문임에도 그 정답의 유형이 완전히 다름을 알 수 있는 예를 한 번 들어보겠습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse; width: 100%;&quot; border=&quot;1&quot; data-ke-style=&quot;style12&quot;&gt;&lt;caption&gt;[표 3] 질의 형태가 비슷한 사례&lt;/caption&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 20%; text-align: center;&quot;&gt;&lt;b&gt;번호&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 20%; text-align: center;&quot;&gt;&lt;b&gt;질의&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 20%; text-align: center;&quot;&gt;&lt;b&gt;정답 유형&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;width: 40%; text-align: center;&quot;&gt;&lt;b&gt;정답&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 20%; text-align: center;&quot;&gt;1&lt;/td&gt;
&lt;td style=&quot;width: 20%;&quot;&gt;경찰서 번호가 뭐야?&lt;/td&gt;
&lt;td style=&quot;width: 20%;&quot;&gt;단답형&lt;/td&gt;
&lt;td style=&quot;width: 40%;&quot;&gt;112&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 20%; text-align: center;&quot;&gt;2&lt;/td&gt;
&lt;td style=&quot;width: 20%;&quot;&gt;원자 번호가 뭐야?&lt;/td&gt;
&lt;td style=&quot;width: 20%;&quot;&gt;서술형&lt;/td&gt;
&lt;td style=&quot;width: 40%;&quot;&gt;주기율표에서 각 원소마다 주어진 원소 고유의 순번&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;[표 3]에서 1번과 2번 문장은 &amp;lsquo;~번호가 뭐야&amp;rsquo;라는 동일한 문형으로 종결됩니다. 1번은 &amp;lsquo;경찰서&amp;rsquo;라는 주제어의 하위 속성에 대한 질문입니다. 따라서 단답형으로 정답이 제공되어야 합니다. 원자 번호라는 주제어에 대한 정의를 질의하는 2번에서는 서술형 정답이 제공되어야 하죠.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;특정 단어 시퀀스에 대한 정답 유형의 단답형 또는 서술형 확률을 구할 때에는 형태소&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_3&quot; href=&quot;#footnote_64_3&quot; onmouseover=&quot;tistoryFootnote.show(this,64,3)&quot; onmouseout=&quot;tistoryFootnote.hide(64,3)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;3&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;, 품사와 같은 정보를 고려합니다. 그런데 품사 정보는 문장을 두 범주 중 하나로 분류하는 데 크게 도움이 되지 않습니다. 즉, '번호가 뭐야'라는 동일한 문형을 가진 두 개의 문장에서 주제어의 형태소만 다른 상황에서는 해당 문장이 요구하는 정답이 단답형일 확률 또는 서술형일 확률은 서로 크게 다르지 않을 것이라는 의미입니다. 이런 이유로 단순한 키워드 나열이나 단문 형태를 취하는 질의 분석만으로는 예상 정답의 유형을 분류하기가 쉽지 않습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;질의 형태의 변형(경찰서 번호가 뭐야, 경찰서 번호 좀 알려줘봐)이나 입력 오류(경칠서 번호가 뭐야, 경찰서 반호가 뭐야) 등 수제 규칙이나 패턴에서 벗어난 질문에 대해서도 적절한 정답을 제공하지 못할 수도 있습니다. 질의를 제대로 분석하지 못해 정답 유형에 따른 적합한 알고리즘을 제대로 호출하지 못하게 되기 때문입니다. 이처럼 대다수의 서비스 이용자가 자신만의 스타일로 문장을 입력한다는 사실을 고려했을 때 패턴이나 규칙에서 벗어난 질의 문장 또한 제대로 분류할 수 있는 강건한 시스템이 필요합니다.&lt;/p&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;BERT 언어 모델을 사용하지 않는 이유&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;기존의 언어 모델에서는 순차 데이터(sequential data)를 다루기 용이한 RNN(recurrent neural network)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_4&quot; href=&quot;#footnote_64_4&quot; onmouseover=&quot;tistoryFootnote.show(this,64,4)&quot; onmouseout=&quot;tistoryFootnote.hide(64,4)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;4&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt; 구조에 주로 기반을 두었습니다. 하지만 이로 인해 병렬 처리(parallel processing)가 어려워 계산 속도가 느려지고, 입력 초기의 데이터를 잊어버리는 경향으로 인해 문장 길이가 길어질수록 성능도 떨어지게 됩니다. 어텐션(attention)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_5&quot; href=&quot;#footnote_64_5&quot; onmouseover=&quot;tistoryFootnote.show(this,64,5)&quot; onmouseout=&quot;tistoryFootnote.hide(64,5)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;5&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;을 통해 위에 언급한 문제가 일정 부분 해소되기는 했으나, 그 단점을 완전히 극복하지는 못했습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;RNN의 한계를 넘어서고자 새롭게 고안된 &lt;a href=&quot;https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf&quot;&gt;Transformer&lt;/a&gt;&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_6&quot; href=&quot;#footnote_64_6&quot; onmouseover=&quot;tistoryFootnote.show(this,64,6)&quot; onmouseout=&quot;tistoryFootnote.hide(64,6)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;6&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;는 거리가 먼 단어 간 관계를 효과적으로 표현하는 셀프 어텐션(self-attention)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_7&quot; href=&quot;#footnote_64_7&quot; onmouseover=&quot;tistoryFootnote.show(this,64,7)&quot; onmouseout=&quot;tistoryFootnote.hide(64,7)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;7&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;을 이용해 학습 시간은 줄이고, 학습 성능은 효과적으로 높였습니다. 이후에 나온 BERT, GPT2를 비롯한 현재 모든 SOTA(state-of-the-art, 현재 최고 수준의) 언어 모델은 바로 이 Transformer 구조에 기반을 둡니다. 문맥에 따라 변하는 단어의 의미를 표현하는 데 탁월한 최신의 이 언어 모델은 다양한 NLP 과제에서 기대 이상의 성능을 선보이고 있습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;하지만 이런 낙관론과는 달리, 실제 서비스 개발 현장에서는 속도 저하를 문제로 최신 언어 모델을 도입하는 사례가 많지 않습니다. 223GB의 한국어 문장을 가지고 CNN(convolutional neural networks)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_8&quot; href=&quot;#footnote_64_8&quot; onmouseover=&quot;tistoryFootnote.show(this,64,8)&quot; onmouseout=&quot;tistoryFootnote.hide(64,8)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;8&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt; 기반 모델과 BERT 기반 모델&lt;span style=&quot;color: #333333;&quot;&gt;&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_9&quot; href=&quot;#footnote_64_9&quot; onmouseover=&quot;tistoryFootnote.show(this,64,9)&quot; onmouseout=&quot;tistoryFootnote.hide(64,9)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;9&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;의 &lt;a href=&quot;https://github.com/dsindex/iclassifier/blob/master/KOR_EXPERIMENTS.md#experiments-summary&quot;&gt;성능을 비교한 실험&lt;/a&gt;이 이를 뒷받침합니다. 성능 차는 거의 없었으나 처리 속도는 수배 이상 차이 났기 때문입니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;보통은 디코더(decoder)를 &lt;a href=&quot;http://eigen.tuxfamily.org/index.php?title=Main_Page&quot;&gt;Eigen&lt;/a&gt;&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_10&quot; href=&quot;#footnote_64_10&quot; onmouseover=&quot;tistoryFootnote.show(this,64,10)&quot; onmouseout=&quot;tistoryFootnote.hide(64,10)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;10&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;로 활용하면 속도를 최적화할 수 있습니다. 다만 모델의 층수가 많아질수록 그 이점은 줄어듭니다. 이런 이유로 BERT처럼 층이 많고 그 구조가 복잡한 모델에서는 서비스가 가능한 수준의 속도 최적화는 매우 어려운 편에 속합니다. 그 결과, BERT 기반 모델은 서버 GPU를 사용하고도 한 문장을 분류하는 데에만 9.3280ms나 걸립니다. 반면, CNN 기반 모델에서는 CPU 싱글코어만으로도 한 문장 분류에 2ms밖에 걸리지 않았죠.&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;AI Lab은 비슷한 정확도를 가진 모델인데, 훨씬 값싸고 빠르게 사용할 수 있다면 공학적인 측면에서 마다할 이유가 없다고 판단, BERT 기반 언어 모델 대신 &lt;a href=&quot;https://nlp.stanford.edu/projects/glove/&quot;&gt;GloVe&lt;/a&gt;[3] 의미 벡터와 어절 임베딩 벡터를 CNN에 입력해 그 문맥을 학습할 수 있도록 했습니다[1]. CNN 기반 모델을 채택한 이유는 뒤에서 자세히 설명해드리겠습니다.&lt;/p&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;AI Lab이 정답 유형을 분류하는 방법&lt;/h2&gt;
&lt;h3 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size23&quot;&gt;1. 전처리&lt;/h3&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;한국어 어절&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_11&quot; href=&quot;#footnote_64_11&quot; onmouseover=&quot;tistoryFootnote.show(this,64,11)&quot; onmouseout=&quot;tistoryFootnote.hide(64,11)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;11&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt; 하나는 두 개 이상의 형태소를 포함하는 경우가 많습니다. 이런 이유로 기존 한국어 관련 많은 연구에서는 한국어 형태소 분석기를 이용해 입력 문장을 형태소 단위로 나누는 데이터 전처리를 실시합니다. AI Lab 또한 규칙과 통계 기반으로 동작하는 자체 한국어 형태소 분석기&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_12&quot; href=&quot;#footnote_64_12&quot; onmouseover=&quot;tistoryFootnote.show(this,64,12)&quot; onmouseout=&quot;tistoryFootnote.hide(64,12)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;12&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;를 이용해 입력 문장에서 형태소와 품사 정보를 추출했습니다.&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;하지만 AI Lab은 형태소를 분석하는 것만으로는 오탈자 여부를 알기가 쉽지 않다고 판단했습니다. 사용자는 비슷하게 발음되는 두 단어를 혼동하거나, 키보드상에서 가까이 위치하는 키를 잘못 타이핑하거나, 단순히 띄어쓰기를 생략할 수도 있습니다. 대부분의 경우, 정상적인 표현에서 자음, 모음 한두 개가 다른 경우가 많습니다. 이에 AI Lab은 자음과 모음 추출기를 이용해 어절의 자모음 정보도 획득했습니다. 이 자모음 정보는 뒤에서 설명할 통합 어절 임베딩(행렬) 생성에 활용됩니다.&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bpLM4Q/btqFHrxz4Ny/JKFKZfUORHnGomnDiPKL41/img.png' data-lightbox='lightbox' data-alt='[그림 2] 전처리 및 통합 어절 임베딩 생성 과정'&gt;&lt;img src='https://blog.kakaocdn.net/dn/bpLM4Q/btqFHrxz4Ny/JKFKZfUORHnGomnDiPKL41/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbpLM4Q%2FbtqFHrxz4Ny%2FJKFKZfUORHnGomnDiPKL41%2Fimg.png' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 2] 전처리 및 통합 어절 임베딩 생성 과정&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size23&quot;&gt;2. 통합 어절 임베딩 생성&lt;/h3&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;자연어 어절을 벡터로 바꾸는 데에는 워드 임베딩(word embedding)을 사용합니다. 워드 임베딩은 대규모 말뭉치에 등장하는 단어의 일반적인 의미를 벡터로 표현합니다. 예를 들어, 의미가 비슷한 '인간'과 '사람'을 비슷한 방식으로 표현할 수 있습니다. 또 &lt;a href=&quot;https://brunch.co.kr/@kakao-it/65&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&amp;lsquo;왕-남자=왕비&amp;rsquo;와 같은 관계&lt;/a&gt;에서 보듯이 단어의 실제적 의미적 차이를 거리로 표현하는 것도 합니다. 대표적인 워드 임베딩 모델로 &lt;a href=&quot;https://code.google.com/archive/p/word2vec/&quot;&gt;Word2Vec&lt;/a&gt;[2], &lt;a href=&quot;http://nlp.stanford.edu/projects/glove/&quot;&gt;GloVe&lt;/a&gt;, &lt;a href=&quot;https://fasttext.cc/&quot;&gt;FastText&lt;/a&gt;[4]가 있습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;AI Lab은 여타 다른 임베딩 기법보다 단어의 의미를 더 잘 담아내는 GloVe 포함한, 입력 오류에 강건한 (자모) 통합 어절 임베딩 생성기를 구축했습니다. 형태소 어휘 사전에 존재하지 않은 오탈자로 인해(out of vocabulary) 형태소 분석 오차(noise)를 최소화하기 위함입니다. 통합 어절 임베딩 생성기는 형태소와 자모음 정보에 각각 부여한 임베딩 벡터를 이용해 다시 원래 어절을 조합하는 과정을 학습합니다. 그 결과, 입력 오류가 발생하더라도 원래 어절을 유사하게 추정할 수 있습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;AI Lab은 통합 어절 임베딩 생성기 훈련 과정에서 자모 드롭아웃(dropout)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_13&quot; href=&quot;#footnote_64_13&quot; onmouseover=&quot;tistoryFootnote.show(this,64,13)&quot; onmouseout=&quot;tistoryFootnote.hide(64,13)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;13&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;과 띄어쓰기 없는 문장 생성이라는 두가지 데이터 노이즈(noise) 생성 기법을 추가했습니다. 기존 시스템 대비 오류가 포함된 문장을 분류하는 성능이 약 23%P 향상되는 등[1] 이 기법의 유효성은 AI Lab 자체 실험을 통해서도 증명이 됐습니다.&lt;/p&gt;
&lt;h3 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size23&quot;&gt;3. 문장 임베딩 벡터 생성&lt;/h3&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;문장에 존재하는 각 어절을 표현하는 임베딩을 추출했다면, 이를 바탕으로 문맥까지 표현하는 임베딩 벡터를 생성할 차례입니다. 여기에는 CNN기반 모델이 활용됩니다.&amp;nbsp;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/bH7fmw/btqFFVsRbwI/sefn3NaslrYykMmQc0v3A0/img.png' data-lightbox='lightbox' data-alt='[그림 3] 문장 임베딩 생성 및 분류'&gt;&lt;img src='https://blog.kakaocdn.net/dn/bH7fmw/btqFFVsRbwI/sefn3NaslrYykMmQc0v3A0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbH7fmw%2FbtqFFVsRbwI%2Fsefn3NaslrYykMmQc0v3A0%2Fimg.png' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 3] 문장 임베딩 생성 및 분류&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size20&quot;&gt;(1) DenseNet&lt;/h4&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;이미지 분류(classification)와 분할(segmentation), 객체 감지(detection)과 같은 비전 문제에서 탁월한 성능을 내는 &lt;a href=&quot;https://ratsgo.github.io/natural%20language%20processing/2017/03/19/CNN/&quot;&gt;CNN은 자연어처리 문제에도 효과적&lt;/a&gt;입니다. 컨볼루션 연산층(convolution layer)의 필터(filter)가 문맥 파악에 중요한 부분만 도출하는 데 유리한 덕분입니다. 그 결과, CNN을 통과한 최종 벡터는 문장의 지역 정보를 보존하는 추상화 과정을 거쳐 단어나 표현의 등장 순서를 반영한 문장의 의미 정보(semantic information)를 표현할 수 있게 됩니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;AI Lab이 문장 분류를 위해 기본으로 사용한 DenseNet[5]은 CNN을 응용한 대표 알고리즘으로, 이전 층에서 생성된 특징 맵(feature map)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_14&quot; href=&quot;#footnote_64_14&quot; onmouseover=&quot;tistoryFootnote.show(this,64,14)&quot; onmouseout=&quot;tistoryFootnote.hide(64,14)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;14&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;을 모두 이어붙여서(concatenation) 다음층에 입력합니다. 컨볼루션 층이 많아질수록 출력 층에서부터 계산된 기울기(gradient)가 전체 네트워크에 올바르게 전달되지 않는 기울기 소실(gradient vanishing)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_15&quot; href=&quot;#footnote_64_15&quot; onmouseover=&quot;tistoryFootnote.show(this,64,15)&quot; onmouseout=&quot;tistoryFootnote.hide(64,15)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;15&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt; 문제를 완화하는 이 로직이 자연어처리에서도 효과적인 방법이라고 AI Lab은 판단했습니다.&amp;nbsp;&lt;/p&gt;
&lt;h4 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size20&quot;&gt;(2) 깊이별 분리 컨볼루션 연산(Depthwise separable convolution)&lt;/h4&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;형태소와 자모 정보를 반영한 통합 어절 임베딩을 모델에 바로 입력하면 전체 학습 시간이 지나치게 길어지는 문제가 발생할 수 있습니다. 각 임베딩별로 컨볼루션 연산이 이뤄지다 보니 매개변수(parameter) 수가 늘어나는 만큼 처리 시간이 비례해서 늘어나기 때문입니다. 따라서 매개변수가 늘어나는 상황에 대비해 학습 속도나 추론 속도를 높일 필요가 있습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;이를 해결하고자 AI Lab은 깊이별 분리 컨볼루션 연산[6]을 이용합니다. 2D 이미지 데이터에 대한 깊이별 분리 컨볼루션은 매개변수 수 최적화를 통해 메모리 사용량은 줄이고 학습 속도를 높입니다. 채널을 기준으로 각각 [필터 높이, 필터 너비, 1]와 [1, 1, 채널 수]로 분리한 두 종류의 새로운 필터로 각각 깊이별 컨볼루션(Depthwise convolution)과 포인트별 컨볼루션(Pointwise convolution) 연산을 순차적으로 진행합니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;이 연구에서 깊이별 컨볼루션은 어절 간 관계를 고려합니다. 주위 어절을 함께 고려한다는 측면에서 n-gram&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_16&quot; href=&quot;#footnote_64_16&quot; onmouseover=&quot;tistoryFootnote.show(this,64,16)&quot; onmouseout=&quot;tistoryFootnote.hide(64,16)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;16&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt; 확률을 분류에 사용하는 것과 비슷하다고 보면 됩니다. 포인트별 컨볼루션은 유효 데이터만 추려내고자 전체 채널을 하나로 압축해 컨볼루션 연산을 진행합니다. 이렇게 하면 연산 속도를 높이는 데 도움이 됩니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;300차원의 통합 어절 임베딩 벡터와 (300*3) 크기의 필터 256개를 이용한 컨볼루션 연산&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_17&quot; href=&quot;#footnote_64_17&quot; onmouseover=&quot;tistoryFootnote.show(this,64,17)&quot; onmouseout=&quot;tistoryFootnote.hide(64,17)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;17&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;이 있다고 가정하겠습니다. 일반적인 필터를 이용한 1회의 컨볼루션 연산에는 총 (입력 채널 수*필터 높이*필터 너비*출력 채널 수)개의 매개변수가 필요합니다. 여기서는 300*1*3*256=230,400개의 매개변수를 연산해야 하죠. 반면, 깊이별 분리 컨볼루션에서는&amp;nbsp; 각각 300*1*3*1=900개와 300*1*1*256=76,800개의 매개변수가 필요합니다. 이를 합치면 총 77,700개로, 연산 효율이 33.7% 더 좋다는 사실을 확인해볼 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; width=&quot;693&quot; height=&quot;NaN&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/b409zf/btqFIitA5OD/Q59nH6CTO2VKdAmKiojPTK/img.png' data-lightbox='lightbox' data-alt='[그림 4] 기존 컨볼루션 연산과 깊이별 분리 컨볼루션에 사용하는 필터 예시'&gt;&lt;img src='https://blog.kakaocdn.net/dn/b409zf/btqFIitA5OD/Q59nH6CTO2VKdAmKiojPTK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb409zf%2FbtqFIitA5OD%2FQ59nH6CTO2VKdAmKiojPTK%2Fimg.png' data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; width=&quot;693&quot; height=&quot;NaN&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 4] 기존 컨볼루션 연산과 깊이별 분리 컨볼루션에 사용하는 필터 예시&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size20&quot;&gt;(3) 동적 셀프 어텐션(dynamic self-attention)&lt;/h4&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;서로 연관성이 높으나 거리상 멀리 떨어진 어절이 서로 참조할 수 있게 하는 기법으로 어텐션이 있습니다. 다만 기존의 어텐션 기법은 입력 발화 길이에 제약이 없는 실제 서비스에 적합하지 않을 수가 있습니다. 어텐션 행렬의 형태가 어절 수에 제약을 받기 때문입니다. 이에 AI Lab은 입력 어절의 수에 관계없이 어텐션 벡터의 계산 및 관리 기법인 동적 셀프 어텐션[7]을 적용했습니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;794&quot; height=&quot;636&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/c0bhmz/btqFHpGvY3x/iPINijOYvjFTpx9YZ2DjeK/img.png' data-lightbox='lightbox' data-alt='[그림 5] 기존 어텐션 기법'&gt;&lt;img src='https://blog.kakaocdn.net/dn/c0bhmz/btqFHpGvY3x/iPINijOYvjFTpx9YZ2DjeK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc0bhmz%2FbtqFHpGvY3x%2FiPINijOYvjFTpx9YZ2DjeK%2Fimg.png' width=&quot;794&quot; height=&quot;636&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 5] 기존 어텐션 기법&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;과정은 다음과 같습니다. 첫 번째, 각 어절 임베딩 벡터와 셀프 어텐션을 나타내는 동적 가중치 벡터(dynamic weight vector)를 곱해 각 어절의 문맥 점수를 구합니다. 두 번째, 각 문맥 점수에 대한 소프트맥스(softmax)&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_18&quot; href=&quot;#footnote_64_18&quot; onmouseover=&quot;tistoryFootnote.show(this,64,18)&quot; onmouseout=&quot;tistoryFootnote.hide(64,18)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;18&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt; 연산을 거치면 중요도 점수(소프트맥스 확률값)를 얻게 됩니다. 세 번째, 어절 임베딩 벡터에 중요도 점수를 가중치로 두고 선형 결합(linear combination)합니다. 네 번째, 이 가중합의 결과는 다시 동적 가중치 벡터로 재정의됩니다. 이 과정을 거치면 어절 길이에 제약을 가진 가중치 행렬을 사용하지 않으면서도 현재 보는 어절과 관련성이 높은 다른 어절의 중요도도 반영할 수 있게 됩니다.&lt;/p&gt;
&lt;p data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;figure class='imageblock alignCenter' width=&quot;794&quot; height=&quot;1413&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/k6EnU/btqFINfBsRk/I1xPyk9uuGT998ik7QbQn0/img.png' data-lightbox='lightbox' data-alt='[그림 6] 동적 셀프 어텐션 과정'&gt;&lt;img src='https://blog.kakaocdn.net/dn/k6EnU/btqFINfBsRk/I1xPyk9uuGT998ik7QbQn0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fk6EnU%2FbtqFINfBsRk%2FI1xPyk9uuGT998ik7QbQn0%2Fimg.png' width=&quot;794&quot; height=&quot;1413&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;figcaption&gt;[그림 6] 동적 셀프 어텐션 과정&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size23&quot;&gt;4. 분류&lt;/h3&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;문장 임베딩 벡터는 마지막 출력층인 FFNN(Feed-forward neural network)과 소프트맥스 연산을 거쳐 사용자 질의문이 요구하는 답변 유형을 단답형 또는 서술형으로 분류합니다.&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size16&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style1&quot; /&gt;
&lt;h2 style=&quot;text-align: justify;&quot; data-ke-size=&quot;size26&quot;&gt;향후 계획&lt;/h2&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;AI Lab은 예기치 않은 오분류 문장을 완전히 제어할 수 있어야 비로소 사용자에게 충분한 만족감을 선사하는 서비스를 제공할 수 있다고 보고 있습니다. 지금까지는 육하원칙, 개체명 인식기, 가젯티어&lt;sup class=&quot;footnote&quot;&gt;&lt;a id=&quot;footnote_link_64_19&quot; href=&quot;#footnote_64_19&quot; onmouseover=&quot;tistoryFootnote.show(this,64,19)&quot; onmouseout=&quot;tistoryFootnote.hide(64,19)&quot; style=&quot;color:#f9650d;font-family:Verdana,Sans-serif;display:inline;&quot;&gt;&lt;span style=&quot;display:none&quot;&gt;[각주:&lt;/span&gt;19&lt;span style=&quot;display:none&quot;&gt;]&lt;/span&gt;&lt;/a&gt;&lt;/sup&gt;와 같은 추가 특징을 딥러닝 분류 모델에 적용했을 때 유의미한 성능 개선을 확인했습니다. 정답 유형 분류에 맞게 미세조정된(fine-tuning)된 BERT 모델을 전문가(teacher)로, CNN을 숙련자(student)로 설정하는 실험에서는 괄목할만한 성능 개선을 이뤘으며 현재 그 결과를 정리하고 있습니다. 이처럼 AI Lab은 정답 유형 분류기의 성능을 개선하기 위한 연구를 앞으로도 계속 진행할 계획입니다.&amp;nbsp;&lt;/p&gt;
&lt;hr contenteditable=&quot;false&quot; data-ke-type=&quot;horizontalRule&quot; data-ke-style=&quot;style6&quot; /&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;참고 문헌&lt;/b&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size14&quot;&gt;[1] 한국어 챗봇에서의 오류에 강건한 한국어 문장 분류를 위한 어절 단위 임베딩 (2019) by 최동현, 박일남, 신명철, 김응균, 신동렬 in 제 31회 한글 및 한국어 정보처리 학술대회 논문집(pp. 43-48)&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size14&quot;&gt;[2] &lt;a href=&quot;https://arxiv.org/abs/1301.3781&quot;&gt;Efficient Estimation of Word Representations in Vector Space&lt;/a&gt; (2013) by Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean in ICLR Workshop&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size14&quot;&gt;[3] &lt;a href=&quot;https://www.aclweb.org/anthology/D14-1162.pdf&quot;&gt;GloVe: Global Vectors for Word Representation&lt;/a&gt; by Jeffrey Pennington, Richard Socher, Christopher D. Manning, in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size14&quot;&gt;[4] &lt;a href=&quot;https://arxiv.org/abs/1607.01759&quot;&gt;Bag of Tricks for Efficient Text Classification&lt;/a&gt; by&amp;nbsp; Armand Joulin, Edouard Grave, Piotr Bojanowski, Tomas Mikolov in arXiv&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size14&quot;&gt;[5] &lt;a href=&quot;http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf&quot;&gt;Densely Connected Convolutional Networks&lt;/a&gt; (2017) by Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger in CVPR&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size14&quot;&gt;[6] &lt;a href=&quot;https://arxiv.org/abs/1704.04861&quot;&gt;MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications&lt;/a&gt; (2017) by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam in CVPR&lt;/p&gt;
&lt;p style=&quot;text-align: justify;&quot; data-ke-size=&quot;size14&quot;&gt;[7] &lt;a href=&quot;https://arxiv.org/abs/1808.07383&quot;&gt;Dynamic Self-Attention: Computing Attention over Words Dynamically for Sentence Embedding&lt;/a&gt; (2018) by Deunsol Yoon, Dongbok Lee, SangKeun Lee in arXiv&lt;/p&gt;
&lt;p data-ke-size=&quot;size14&quot;&gt;&amp;nbsp;&lt;/p&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' data-filename=&quot;samantha.her_이수경_trimmed.jpg&quot; data-origin-width=&quot;375&quot; data-origin-height=&quot;375&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/cRx0RG/btqFp4hZ3ra/cN7i1LXsNhUt5zfzVd3yY1/img.jpg' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/cRx0RG/btqFp4hZ3ra/cN7i1LXsNhUt5zfzVd3yY1/img.jpg' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcRx0RG%2FbtqFp4hZ3ra%2FcN7i1LXsNhUt5zfzVd3yY1%2Fimg.jpg' data-filename=&quot;samantha.her_이수경_trimmed.jpg&quot; data-origin-width=&quot;375&quot; data-origin-height=&quot;375&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;이수경(samantha) | 작성, 편집&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;지난 2016년 3월 알파고와 이세돌 9단이 펼치는 세기의 대결을 취재한 것을 계기로 인공지능 세계에 큰 매력을 느꼈습니다. 카카오엔터프라이즈에서 인공지능을 제대로 알고 싶어하는 사람들을 위해 전문가와 함께 읽기 쉬운 콘텐츠를 쓰고 있습니다. 인공지능을 만드는 사람들의 이야기와 인공지능이 바꿀 미래 사회에 대한 글은 누구보다 쉽고, 재미있게 쓰는 사람이 되고자 합니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;351&quot; height=&quot;351&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/ty6Pz/btqFpMhyRly/WxxiKVoSk3FLc9B9E5WIo0/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/ty6Pz/btqFpMhyRly/WxxiKVoSk3FLc9B9E5WIo0/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fty6Pz%2FbtqFpMhyRly%2FWxxiKVoSk3FLc9B9E5WIo0%2Fimg.png' width=&quot;351&quot; height=&quot;351&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;조승우(john) | 작성, 감수&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;친구들과 함께 빅데이터 감정 분석 프로젝트를 수행하며 자연어처리에 큰 흥미를 느낀 것을 계기로 학부 때는 데이터마이닝 연구실에서 빅데이터 관련 연구를, 석사 때는 기계번역과 문법 교정 관련 연구를 진행했습니다. 현재 카카오엔터프라이즈에서는 카카오 i 대화 엔진에 필요한 개체명을 인식하는 딥러닝 모델과 정답 유형 분류 딥러닝 모델 개발을 맡고 있습니다. 앞으로의 인공지능은 사람의 번거로운 일을 해소하는 데 영향력을 발휘했으면 좋겠습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-author&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;figure class='imageblock alignCenter' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;span data-url='https://blog.kakaocdn.net/dn/tLnpW/btqFIimR4Ec/jFsyJAMyiKkmr3ZlA2QwoK/img.png' data-lightbox='lightbox' data-alt=''&gt;&lt;img src='https://blog.kakaocdn.net/dn/tLnpW/btqFIimR4Ec/jFsyJAMyiKkmr3ZlA2QwoK/img.png' srcset='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtLnpW%2FbtqFIimR4Ec%2FjFsyJAMyiKkmr3ZlA2QwoK%2Fimg.png' width=&quot;200&quot; height=&quot;200&quot; data-origin-width=&quot;0&quot; data-origin-height=&quot;0&quot; data-ke-mobilestyle=&quot;widthContent&quot;&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/div&gt;
&lt;div class=&quot;txt&quot;&gt;
&lt;p class=&quot;name&quot;&gt;최동현(heuristic) | 감수&lt;/p&gt;
&lt;p class=&quot;desc&quot; style=&quot;text-align: justify;&quot;&gt;어느새 30대 중반으로 접어든, 그러나 마음만은 젊게 지내는 인공지능 개발자입니다. 2017년에 카카오로 이직하며 카카오미니 개발에 참여하게 되었습니다. 카카오미니에 기여를 할 수 있어서 매우 기쁘고 미니를 좀 더 똑똑하게 만들기 위하여 열심히 공부 중에 있습니다.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;kep-recruit&quot;&gt;&lt;img class=&quot;img-recruit&quot; src=&quot;https://mk.kakaocdn.net/dn/kep-web/kep-blog/img_recruit.png&quot; /&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;b&gt;새로운 길에 도전하는 최고의 Krew들과 함께 해요!&lt;/b&gt;&lt;/p&gt;
&lt;p data-ke-size=&quot;size18&quot;&gt;&lt;a href=&quot;https://kakaoenterprise.recruiter.co.kr/app/jobnotice/view?systemKindCode=MRS2&amp;amp;jobnoticeSn=16933&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[AI기술] 자연어 처리 전문가 모집&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;div class=&quot;footnotes&quot;&gt;
&lt;ol class=&quot;footnotes&quot;&gt;
&lt;li id=&quot;footnote_64_1&quot;&gt; 사용자의 발화를 인식해 적절한 서비스를 연결해주는 자연어처리기술 &lt;a href=&quot;#footnote_link_64_1&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_2&quot;&gt; 문장을 구성하는 문장성분의 배열 유형 &lt;a href=&quot;#footnote_link_64_2&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_3&quot;&gt; 뜻을 지니는 최소의 단위 &lt;a href=&quot;#footnote_link_64_3&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_4&quot;&gt; N 단계에서의 값을 다시 입력값으로 사용해 N+1단계에서의 상태를 예측하는 재귀적(recursive)인 구조를 갖춘 신경망 &lt;a href=&quot;#footnote_link_64_4&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_5&quot;&gt; 인코더-디코더 구조의 모델이 특정 시퀀스를 디코딩할 때 관련된 인코딩 결과값을 참조한다. &lt;a href=&quot;#footnote_link_64_5&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_6&quot;&gt; 컨볼루션(convolution)이나 순환(recurrence) 기법 대신, 모든 단어가 현재 결과에 기여하는 정도를 반영할 수 있도록 각 입력 단어가 출력 상태에 연결하는 어텐션(attention) 신경망 구조를 활용한 seq2seq 모델이다. &lt;a href=&quot;#footnote_link_64_6&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_7&quot;&gt; 현재 처리하는 단어와 연관성이 높은 단어를 참조하는 기법 &lt;a href=&quot;#footnote_link_64_7&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_8&quot;&gt; 이미지의 공간 정보를 유지하면서 특징을 효과적으로 인식하고 강조하는 딥러닝 모델. 특징을 추출하는 영역은 컨볼루션 층과 풀링 층으로 구성된다. 컨볼루션 층은 필터를 사용해 공유 파라미터 수를 최소화하면서 이미지의 특징을 찾는다. 풀링 층은 특징을 강화하고 모은다. &lt;a href=&quot;#footnote_link_64_8&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_9&quot;&gt; 형태소 분석기 대신 최신 단어 분절 알고리즘인 BPE를 사용했다. &lt;a href=&quot;#footnote_link_64_9&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_10&quot;&gt; C++ 선형대수 연산 라이브러리 &lt;a href=&quot;#footnote_link_64_10&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_11&quot;&gt; 문장 성분의 최소 단위. 띄어쓰기의 단위가 된다. &lt;a href=&quot;#footnote_link_64_11&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_12&quot;&gt; AI lab은 뜻을 지니는 최소 단위인 형태소로 우선 안정적으로 분류 실험을 진행하고 나서, 서브워드(subword) 단위로 문장을 분절하는 최신 기법인 BPE를 활용한 연구도 진행하고 있다. &lt;a href=&quot;#footnote_link_64_12&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_13&quot;&gt; 특정 자모가 포함된 임베딩 벡터값을 전부 0으로 변환하는 기법 &lt;a href=&quot;#footnote_link_64_13&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_14&quot;&gt; 컨볼루션 연산으로 얻은 결과 &lt;a href=&quot;#footnote_link_64_14&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_15&quot;&gt; 역전파 알고리즘에서는 낮은 층으로 갈수록 전파되는 오류(error)의 양이 적어진다. 이로 인해 미분값의 변화가 거의 없어져 학습이 제대로 일어나지 않는다. &lt;a href=&quot;#footnote_link_64_15&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_16&quot;&gt; 어떤 한 입력을 처리할 때 N개의 입력 단위(토큰(token))를 함께 볼지를 결정한다. 이 글에서는 통합 어절 임베딩을 생성하기에 어절을 하나의 입력 단위로 취급한다. &lt;a href=&quot;#footnote_link_64_16&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_17&quot;&gt; 패딩(padding)은 같게, 스트라이드(stride)는 1인 조건에서 컨볼루션 연산 20회를 수행한다. &lt;a href=&quot;#footnote_link_64_17&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_18&quot;&gt; 다범주 분류기에서는 출력값을 제대로 해석하고자 다른 출력 노드와의 상대적인 크기를 비교한다. 이를 위해 각 출력 노드를 0~1 사이로 제한해 이를 합한 값을 1로 만든다. &lt;a href=&quot;#footnote_link_64_18&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;li id=&quot;footnote_64_19&quot;&gt; 사람이 관리하는 사전 정보로, 보통은 CRF 같은 알고리즘에서 기계학습 성능이 더 높게 나올 수 있도록 수치값을 조정해주는 역할을 맡고 있다. &lt;a href=&quot;#footnote_link_64_19&quot;&gt;[본문으로]&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
<category>Tech Log</category>
<category>AI Lab</category>
<category>BERT</category>
<category>CNN</category>
<category>NLP</category>
<category>대화 엔진</category>
<category>정답 유형</category>
<category>카카오 i</category>
<category>카카오엔터프라이즈</category>
<category>카카오엔터프라이즈채용</category>
<category>컨볼루션</category>
<author>samantha.her</author>
<guid isPermaLink="true">https://tech.kakaoenterprise.com/64</guid>
<comments>https://tech.kakaoenterprise.com/64#entry64comment</comments>
<pubDate>Fri, 24 Jul 2020 13:23:01 +0900</pubDate>
</item>
</channel>
</rss>